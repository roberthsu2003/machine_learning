# 評估指標

在機器學習中，評估指標是用來衡量模型性能的工具。不同的任務類型需要不同的評估指標。以下是一些常用的評估指標，並根據任務類型進行分類。

## 評估指標概述

評估指標用於量化分類模型的性能，通過比較模型預測結果與實際結果來衡量其效果。這些指標幫助我們了解模型在區分不同類別、識別模式以及對新數據的泛化能力方面的表現。每個指標有其特定目的，例如測量整體正確性、聚焦特定類別的性能或平衡相互競爭的目標。理解這些指標的目的有助於在不同任務場景中選擇合適的評估方法，特別是在類別分佈不均衡或特定錯誤代價較高的情況下。

### 關鍵術語：TP、TN、FP、FN

以下術語是許多分類指標的基礎，源自於混淆矩陣，用於總結模型的預測結果：

- **真正例 (True Positive, TP)**：模型正確預測為正類的樣本（例如，正確識別出患病的患者）。

- **真負例 (True Negative, TN)**：模型正確預測為負類的樣本（例如，正確識別出健康的患者）。

- **假正例 (False Positive, FP)**：模型錯誤地預測為正類的樣本（例如，將健康患者誤判為患病，也稱為“第一類錯誤”）。

- **假負例 (False Negative, FN)**：模型錯誤地預測為負類的樣本（例如，將患病患者誤判為健康，也稱為“第二類錯誤”）。

這些術語對於理解模型的正確預測和錯誤類型如何影響性能至關重要。



## 分類任務

**➜準確率 (Accuracy)**：正確分類的樣本數佔總樣本數的比例。  
- **目的**:評估模型在所有類別上的整體正確性，適用於類別分佈均衡的數據集。  
- **公式**：`Accuracy = (TP + TN) / (TP + TN + FP + FN)`  
- **使用場景**：在垃圾郵件檢測中，當垃圾郵件和非垃圾郵件的數量相近時，準確率可有效衡量模型表現。  
- **限制**: 在不均衡數據集中可能具有誤導性（例如，若 95% 的樣本為負類，模型預測所有樣本為負類仍可獲得 95% 的準確率，但無法識別正類）。  
- [**範例**](accuracy.ipynb)  

**➜精確率 (Precision)**：在所有預測為正類的樣本中，實際為正類的比例。  
- **目的**：評估正類預測的可靠性，適用於假正例代價較高的場景（例如，避免錯誤診斷疾病）。   
- **公式**：`Precision = TP / (TP + FP)`   
- **使用場景**: 在詐欺檢測中，高精確率確保被標記的交易很可能是詐欺交易，從而減少不必要的調查。  
- **限制**：不考慮遺漏的正例（召回率低）。  
- [範例](precision.ipynb)  

**➜召回率 (Recall, Sensitivity)**：在所有實際為正類的樣本中，被正確預測為正類的比例。    
- **目的**:評估模型捕捉所有正類樣本的能力，適用於假負例代價較高的場景（例如，避免漏診疾病）。  
- **公式**：`Recall = TP / (TP + FN)`  
- **使用場景**: 在癌症篩查中，高召回率確保大多數癌症患者被識別，即使可能出現一些假正例。  
- **限制**: 不考慮假正例（精確率低）。  
- [**範例**](recall.ipynb)  

**➜F1 分數 (F1-score)**：精確率和召回率的調和平均數，提供平衡兩者的單一指標。  
- **目的**：當假正例和假負例均重要時，用於綜合考量精確率和召回率的權衡。  
- **公式**：`F1-score = 2 * (Precision * Recall) / (Precision + Recall)`  
- **使用場景**: 在信息檢索（如搜索引擎）中，F1 分數平衡返回相關結果（精確率）與涵蓋所有相關結果（召回率）。  
- **限制**：若精確率或召回率之一顯著更重要，F1 分數可能不夠理想。  
- [**範例**](f1_score.ipynb)  

**➜AUC-ROC 曲線 (AUC-ROC Curve)**：接收者操作特徵曲線 (ROC) 下的面積，用於評估二元分類器的整體性能。    
- **目的**：衡量模型在不同分類閾值下區分正負類的能力，AUC 值越大表示模型性能越好。  
- **使用場景**：在信用風險評估等二元分類任務中，AUC-ROC 衡量模型區分高風險和低風險客戶的能力。  
- **限制**：在高度不均衡的數據集中可能不夠直觀，此時精確率-召回率曲線更合適。  
- [**範例**](auc_roc_curve.ipynb)  

**➜混淆矩陣 (Confusion Matrix)**：以表格形式展示 TP、TN、FP、FN 的數量，全面呈現模型的預測性能。  
- **目的**:提供詳細的分類錯誤和正確預測分析，是計算其他指標的基礎。  
- **使用場景**：在多類別問題（如圖像分類）中，混淆矩陣揭示哪些類別容易被混淆。  
- [**範例**](confusion_matrix.ipynb)  

## 迴歸任務評估指標

**評估指標概述**

迴歸任務的評估指標用於衡量模型預測連續數值與實際值之間的誤差和一致性。這些指標幫助我們評估模型在擬合數據、捕捉數據模式以及對新數據的泛化能力方面的表現。每個指標有其特定的目的，例如測量預測誤差的大小、強調大誤差的影響或評估模型對數據變異性的解釋能力。理解這些指標的目的有助於選擇適合特定任務的評估方法，特別是在誤差分佈或應用場景要求不同時。


**➜平均絕對誤差 (Mean Absolute Error, MAE)**：預測值與實際值之間絕對誤差的平均值。

- **目的**：衡量模型預測的平均誤差大小，提供直觀的誤差度量，單位與原始數據一致。適用於需要均勻處理所有誤差的場景。  
- **公式**：MAE = (1/n) * Σ|y_i - ŷ_i|  
- **使用場景**：在房價預測中，MAE 表示預測價格與實際價格的平均絕對偏差，易於解釋給非技術人員。  
- **限制**：對大誤差不敏感，可能無法充分反映異常值對模型性能的影響。  
- [**範例**](mae.ipynb)


**➜均方誤差 (Mean Squared Error, MSE)**：預測值與實際值之間差的平方的平均值。

- **目的**：通過平方誤差，強調較大的預測誤差對模型性能的影響，適用於大誤差代價較高的場景。  
- **公式**：MSE = (1/n) * Σ(y_i - ŷ_i)^2  
- **使用場景**：在電力負載預測中，MSE 可突出較大預測誤差（如用電高峰預測失誤），因為這些誤差可能導致重大成本。  
- **限制**：對異常值過於敏感，且結果的單位是原始數據單位的平方，解釋性較差。  
- [**範例**](mse.ipynb)


**➜均方根誤差 (Root Mean Squared Error, RMSE)**：均方誤差的平方根。

- **目的**：在保留 MSE 對大誤差敏感的特性同時，將誤差單位還原為與原始數據一致，提供更直觀的誤差度量。  
- **公式**：RMSE = √(MSE)
- **使用場景**：在氣溫預測中，RMSE 表示預測溫度的平均誤差（以攝氏度為單位），便於比較模型性能。
- **限制**：仍對異常值敏感，可能受極端值影響較大。
- [**範例**](rmse.ipynb)


**➜R 平方 (R-squared)**：衡量模型解釋數據變異性的比例。

- **目的**：評估模型對數據變異性的解釋能力，值越接近 1 表示模型越能擬合數據。適用於比較不同模型的擬合效果。  
- **公式**：R² = 1 - (Σ(y_i - ŷ_i)^2 / Σ(y_i - ȳ)^2)，其中 ȳ 為實際值的平均值。  
- **使用場景**：在銷售額預測中，R 平方顯示模型解釋了多少銷售額的變異，有助於判斷模型是否捕捉關鍵趨勢。  
- **限制**：對模型的誤差分佈不敏感，且在非線性關係或數據點較少時可能誤導。
- [**範例**](r_squared.ipynb)
