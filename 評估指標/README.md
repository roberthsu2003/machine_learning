# 評估指標

在機器學習中，評估指標是用來衡量模型性能的工具。不同的任務類型需要不同的評估指標。以下是一些常用的評估指標，並根據任務類型進行分類。

## 評估指標概述

評估指標用於量化分類模型的性能，通過比較模型預測結果與實際結果來衡量其效果。這些指標幫助我們了解模型在區分不同類別、識別模式以及對新數據的泛化能力方面的表現。每個指標有其特定目的，例如測量整體正確性、聚焦特定類別的性能或平衡相互競爭的目標。理解這些指標的目的有助於在不同任務場景中選擇合適的評估方法，特別是在類別分佈不均衡或特定錯誤代價較高的情況下。

### 關鍵術語：TP、TN、FP、FN

以下術語是許多分類指標的基礎，源自於混淆矩陣，用於總結模型的預測結果：

- **真正例 (True Positive, TP)**：模型正確預測為正類的樣本（例如，正確識別出患病的患者）。

- **真負例 (True Negative, TN)**：模型正確預測為負類的樣本（例如，正確識別出健康的患者）。

- **假正例 (False Positive, FP)**：模型錯誤地預測為正類的樣本（例如，將健康患者誤判為患病，也稱為“第一類錯誤”）。

- **假負例 (False Negative, FN)**：模型錯誤地預測為負類的樣本（例如，將患病患者誤判為健康，也稱為“第二類錯誤”）。

這些術語對於理解模型的正確預測和錯誤類型如何影響性能至關重要。

**➜混淆矩陣 (Confusion Matrix)**：以表格形式展示 TP、TN、FP、FN 的數量，全面呈現模型的預測性能。  
- **目的**:提供詳細的分類錯誤和正確預測分析，是計算其他指標的基礎。  
- **使用場景**：在多類別問題（如圖像分類）中，混淆矩陣揭示哪些類別容易被混淆。  
- [**範例**](confusion_matrix.ipynb)  



## 1️⃣分類任務

**➜準確率 (Accuracy)**：正確分類的樣本數佔總樣本數的比例。  
- **目的**:評估模型在所有類別上的整體正確性，適用於類別分佈均衡的數據集。  
- **公式**：`Accuracy = (TP + TN) / (TP + TN + FP + FN)`  
- **使用場景**：在垃圾郵件檢測中，當垃圾郵件和非垃圾郵件的數量相近時，準確率可有效衡量模型表現。  
- **限制**: 在不均衡數據集中可能具有誤導性（例如，若 95% 的樣本為負類，模型預測所有樣本為負類仍可獲得 95% 的準確率，但無法識別正類）。  
- [**範例**](accuracy.ipynb)  

**➜精確率 (Precision)**：在所有預測為正類的樣本中，實際為正類的比例。  
- **目的**：評估正類預測的可靠性，適用於假正例代價較高的場景（例如，避免錯誤診斷疾病）。   
- **公式**：`Precision = TP / (TP + FP)`   
- **使用場景**: 在詐欺檢測中，高精確率確保被標記的交易很可能是詐欺交易，從而減少不必要的調查。  
- **限制**：不考慮遺漏的正例（召回率低）。  
- [範例](precision.ipynb)  

**➜召回率 (Recall, Sensitivity)**：在所有實際為正類的樣本中，被正確預測為正類的比例。    
- **目的**:評估模型捕捉所有正類樣本的能力，適用於假負例代價較高的場景（例如，避免漏診疾病）。  
- **公式**：`Recall = TP / (TP + FN)`  
- **使用場景**: 在癌症篩查中，高召回率確保大多數癌症患者被識別，即使可能出現一些假正例。  
- **限制**: 不考慮假正例（精確率低）。  
- [**範例**](recall.ipynb)  

**➜F1 分數 (F1-score)**：精確率和召回率的調和平均數，提供平衡兩者的單一指標。  
- **目的**：當假正例和假負例均重要時，用於綜合考量精確率和召回率的權衡。  
- **公式**：`F1-score = 2 * (Precision * Recall) / (Precision + Recall)`  
- **使用場景**: 在信息檢索（如搜索引擎）中，F1 分數平衡返回相關結果（精確率）與涵蓋所有相關結果（召回率）。  
- **限制**：若精確率或召回率之一顯著更重要，F1 分數可能不夠理想。  
- [**範例**](f1_score.ipynb)  

**➜AUC-ROC 曲線 (AUC-ROC Curve)**：接收者操作特徵曲線 (ROC) 下的面積，用於評估二元分類器的整體性能。    
- **目的**：衡量模型在不同分類閾值下區分正負類的能力，AUC 值越大表示模型性能越好。  
- **使用場景**：在信用風險評估等二元分類任務中，AUC-ROC 衡量模型區分高風險和低風險客戶的能力。  
- **限制**：在高度不均衡的數據集中可能不夠直觀，此時精確率-召回率曲線更合適。  
- [**範例**](auc_roc_curve.ipynb)  



## 2️⃣迴歸任務評估指標

**評估指標概述**

迴歸任務的評估指標用於衡量模型預測連續數值與實際值之間的誤差和一致性。這些指標幫助我們評估模型在擬合數據、捕捉數據模式以及對新數據的泛化能力方面的表現。每個指標有其特定的目的，例如測量預測誤差的大小、強調大誤差的影響或評估模型對數據變異性的解釋能力。理解這些指標的目的有助於選擇適合特定任務的評估方法，特別是在誤差分佈或應用場景要求不同時。

---

### ➜ 什麼是資料變異性(Data variability)？

資料變異性是指數據點與平均值之間的差異程度。簡單來說，就是數據分散的程度。

**實際例子:**
假設我們有以下薪資數據：

|姓名|薪資|
|--|--|
|小明|30,000|
|小華|32,000|
|小美|31,000|
|小強|45,000|
|小菁|32,000|

**➜分析:**

1. 低變異性的例子
    - 如果去掉小強，其他人的薪資都在 30,000-32,000 之間
    - 這就是低變異性，數據很集中

2. 高變異性的例子
    - 加入小強的 45,000 後，數據變得比較分散
    - 這就形成了高變異性

**➜ R平方與變異性的關係**

**如果 R² = 0.95，表示** 
 
- 模型可以解釋 95% 的薪資變化
- 只有 5% 的變異是模型無法解釋的
- 低變異性

**➜ 視覺化理解**  

想像一張散點圖:

- 點越集中在一條線上 = 低變異性 = 較高的 R²
- 點越分散 = 高變異性 = 較低的 R²

這就像是在觀察：「年資越高，薪資是否真的越高？」的關係程度。

---

**➜ **R平方分數(R² Score)的功能與意義:**衡量模型解釋數據變異性的比例。

### R平方分數(R² Score)的功能與意義:：

- R平方(R²)是一個介於0到1之間的數值，用來衡量迴歸模型的預測效果  
- 它告訴我們模型能解釋多少百分比的資料變異性(請參考資料變異性)

**數值的意義:**  

- R² = 1: 完美預測,模型解釋了100%的變異
- R² = 0: 模型的預測不比直接用平均值更好
- R² < 0: 模型預測效果比用平均值還差

**以薪資預測模型為例:**：

- 如果R² = 0.95,表示:
    - 模型可以解釋95%的薪資變異
    - 表示年資與薪資之間有很強的線性關係
    - 這是一個很好的擬合結果
    - 
**使用時機**

- 用於評估迴歸模型的整體表現
- 比較不同模型的預測效果
- 判斷特徵(如年資)是否能良好解釋目標變數(如薪資)的變化

- **限制**：對模型的誤差分佈不敏感，且在非線性關係或數據點較少時可能誤導。
- [**範例**](r_squared.ipynb)

---
### ➜均方誤差 (Mean Squared Error, MSE)：預測值與實際值之間差的平方的平均值。

1. **為什麼叫「均方誤差」**

名稱由三個部分組成:

- 均:平均值
- 方:平方
- 誤差:預測值與實際值的差距

2. **評估功能**  

	- **計算方式**: `MSE = (1/n) * Σ(y實際 - y預測)²`
	- **目的**:
	    - 評估預測值與實際值的差距大小
	    - 通過平方放大較大的誤差
	    - **結果越小代表模型預測越準確**


3. **範例說明**

```
# 假設我們預測3個學生的成績:
實際成績 = [85, 90, 95]
預測成績 = [80, 88, 98]

# 計算MSE步驟:
1. 計算差距: [5, 2, -3]
2. 平方: [25, 4, 9]  
3. 平均: (25 + 4 + 9) / 3 = 12.67

MSE = 12.67
```  

- [**範例**](mse.ipynb)

---
### ➜均方根誤差 (Root Mean Squared Error, RMSE)：均方誤差的平方根。

**1. 為什麼叫RMSE?**  
RMSE (Root Mean Squared Error) 名稱由三個部分組成:

- Root: 根號 (開根號)
- Mean: 平均
- Squared Error: 平方誤差

**2. 評估功能**
- 衡量模型預測值與實際值之間的平均誤差大小
- 公式: RMSE = √((1/n) * Σ(y實際 - y預測)²)
- 單位與原始數據相同，更容易解釋

**3. 和 MSE 的主要差別**

**➜MSE (均方誤差):**
- 單位是原始數據的平方 (例如: 薪資²)
- 不容易直觀理解誤差大小

**➜RMSE (均方根誤差):**
- 透過開根號，把單位轉回原始數據單位 (例如: 薪資)
- 更容易解釋預測誤差的實際意義

**4. 簡單範例**

```
# 假設在預測薪資
實際薪資 = [30000, 35000, 40000]
預測薪資 = [32000, 34000, 38000]

# 計算MSE步驟
1. 計算差距平方: [(32000-30000)², (34000-35000)², (38000-40000)²]
2. 平均: MSE = 4,000,000

# 計算RMSE
RMSE = √4,000,000 = 2,000

# 解釋:平均預測誤差約2,000元
```

---

### ➜平均絕對誤差 (Mean Absolute Error, MAE)：預測值與實際值之間絕對誤差的平均值。

**1. 為什麼叫MAE**

MAE 是 "Mean Absolute Error" 的縮寫：
- Mean (平均)
- Absolute (絕對值)
- Error (誤差)

**2. 評估目的**  
- 衡量模型預測值與實際值之間的平均誤差大小
- 使用絕對值來計算誤差，所以誤差單位與原始數據一致
- 計算公式：`MAE = (1/n) * Σ|y實際 - y預測|`

**3. 簡單範例**

假設我們在預測學生的考試成績：

```
# 實際成績
y實際 = [85, 90, 95]

# 模型預測成績
y預測 = [87, 88, 98]

# 計算絕對誤差
|85-87| = 2
|90-88| = 2
|95-98| = 3

# MAE計算
MAE = (2 + 2 + 3) / 3 = 2.33
```

這表示模型預測的成績平均會差 2.33 分。MAE 的優點是結果容易理解，因為單位與原始數據相同。 

- [**範例**](mae.ipynb)

---









