{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8641f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "wget.download(\"https://github.com/roberthsu2003/machine_learning/raw/refs/heads/main/source_data/ChineseFont.ttf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6629bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.font_manager import fontManager\n",
    "fontManager.addfont(\"ChineseFont.ttf\")\n",
    "mpl.rc('font', family=\"ChineseFont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecbe98",
   "metadata": {},
   "source": [
    "## 使用特徵比較多的威斯康辛州乳癌資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee0283",
   "metadata": {},
   "source": [
    "## 說明\n",
    "max_iter的意思?\n",
    "1. 優化過程\n",
    "   - 邏輯迴歸使用梯度下降等優化算法來找到最佳的模型參數\n",
    "   - 每次迭代都是調整模型參數的一個步驟\n",
    "   - 目標是最小化損失函數（通常是對數損失）\n",
    "2. 完整數據集的使用\n",
    "   - 在每次迭代中，算法都會使用完整的訓練數據集\n",
    "   - 這表示在一次迭代中，所有訓練樣本都被用來更新模型參數\n",
    "\n",
    "3. 停止條件\n",
    "   - 當算法達到收斂（模型參數幾乎不再變化）時會提前停止\n",
    "   - 如果達到 max_iter 設定的1000次仍未收斂，則強制停止"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea54715",
   "metadata": {},
   "source": [
    "### `fit_transform()`\n",
    "- 這個方法會**同時執行兩個步驟**：\n",
    "  1. **fit (擬合)**：計算訓練數據的統計量（平均值和標準差）\n",
    "  2. **transform (轉換)**：使用計算出的統計量來標準化數據\n",
    "- 主要用於**訓練數據集**\n",
    "- 只能在訓練集上使用一次\n",
    "\n",
    "### `transform()`\n",
    "- 只執行**轉換步驟**\n",
    "- 使用之前 `fit_transform` 時計算好的統計量來進行標準化\n",
    "- 用於**測試數據集**\n",
    "- 可以重複使用在不同的數據集上\n",
    "\n",
    "### 為什麼要這樣區分？\n",
    "1. **數據洩漏問題**：\n",
    "   - 如果在測試集上使用 `fit_transform()`，會導致模型看到測試數據的分布，造成數據洩漏\n",
    "   - 正確做法是只用訓練集的統計量來轉換測試集\n",
    "\n",
    "2. **一致性**：\n",
    "   - 確保測試集使用相同的縮放參數\n",
    "   - 保持訓練集和測試集的轉換標準一致\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca9af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練時的分數:0.988\n",
      "測試時的分數:0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "# Scale the data 將數據進行標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000).fit(X_train_scaled, y_train)\n",
    "print(\"訓練時的分數:{:.3f}\".format(logreg.score(X_train_scaled, y_train)))\n",
    "print(\"測試時的分數:{:.3f}\".format(logreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9bb6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練時的分數:0.998\n",
      "測試時的分數:0.944\n"
     ]
    }
   ],
   "source": [
    "## 調整c參數\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "# Scale the data 將數據進行標準化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "logreg100 = LogisticRegression(max_iter=1000,C=100).fit(X_train_scaled, y_train)\n",
    "print(\"訓練時的分數:{:.3f}\".format(logreg100.score(X_train_scaled, y_train)))\n",
    "print(\"測試時的分數:{:.3f}\".format(logreg100.score(X_test_scaled, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
