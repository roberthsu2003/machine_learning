# 機器學習名詞解釋

## 📚 目錄

### 1. 學習範式
- [1.1 監督式學習（Supervised Learning）](#1-監督式學習supervised-learning)
- [1.2 非監督式學習（Unsupervised Learning）](#2-非監督式學習unsupervised-learning)
- [1.3 總結與比較](#總結與比較)

### 2. 模型參數
- [2.1 參數（Parameters）](#1-參數parameters)
- [2.2 超參數（Hyperparameters）](#2-超參數hyperparameters)
- [2.3 參數與超參數的區別](#3-參數與超參數的區別)

### 3. 數據結構
- [3.1 特徵（Features）](#1-特徵features)
- [3.2 標籤（Labels）](#2-標籤labels)
- [3.3 簡單範例](#簡單範例)

### 4. 數據分割
- [4.1 訓練集（Training Set）](#1-訓練集training-set)
- [4.2 測試集（Test Set）](#2-測試集test-set)
- [4.3 分割的目的](#分割的目的)
- [4.4 簡單範例](#簡單範例-1)

### 5. 模型性能問題
- [5.1 欠擬合（Underfitting）](#1-欠擬合underfitting)
- [5.2 過度擬合（Overfitting）](#2-過度擬合overfitting)
- [5.3 總結與解決方案](#總結與解決方案)

### 6. 模型泛化
- [6.1 模型的泛化（Generalization）](#模型的泛化generalization)
- [6.2 對比欠擬合與過度擬合](#對比欠擬合與過度擬合)
- [6.3 實現良好泛化的方法](#實現良好泛化的方法)

### 7. 評估指標
- [7.1 分類指標](#分類指標)
- [7.2 回歸指標](#回歸指標)
- [7.3 混淆矩陣](#混淆矩陣)

### 8. 特徵工程
- [8.1 特徵選擇](#特徵選擇)
- [8.2 特徵縮放](#特徵縮放)
- [8.3 編碼方式](#編碼方式)

### 9. 優化算法
- [9.1 梯度下降法](#梯度下降法)
- [9.2 學習率](#學習率)
- [9.3 批次大小](#批次大小)

### 10. 常見算法
- [10.1 K-近鄰](#k-近鄰)
- [10.2 決策樹](#決策樹)
- [10.3 支援向量機](#支援向量機)
- [10.4 樸素貝氏](#樸素貝氏)

### 11. 集成學習
- [11.1 Bagging](#bagging)
- [11.2 Boosting](#boosting)
- [11.3 Stacking](#stacking)

### 12. 機器學習訓練過程
- [12.1 ML的整個「訓練過程」](#ml的整個訓練過程這裡以監督式學習supervised-learning為例)
- [12.2 泛化能力說明](#泛化generalize指ml模型對未知資料集的預測能力)
- [12.3 欠擬合與過度擬合比較表](#-欠擬合underfitting--與-過度擬合overfitting)
- [12.4 圖解說明](#用圖簡單解釋-欠擬合underfitting--與-過度擬合overfitting)

---

## 監督式學習（Supervised Learning）和 非監督式學習（Unsupervised Learning）

在機器學習中，監督式學習（Supervised Learning）和非監督式學習（Unsupervised Learning）是兩種主要的學習範式。

---

### 1. 監督式學習（Supervised Learning）
**描述**：  
監督式學習是指使用帶有標籤（即已知輸出或目標變量）的訓練數據來訓練模型。模型通過學習輸入特徵與對應標籤之間的關係，來預測新數據的輸出。監督式學習的目標是讓模型能夠對未見數據進行準確預測或分類。

**特徵**：
- 數據包含輸入特徵 \( X \) 和對應的標籤 \( y \)。
- 訓練目標是最小化預測值與真實標籤之間的誤差。
- 主要任務包括：
  - **分類（Classification）**：預測離散類別（如垃圾郵件或非垃圾郵件）。
  - **回歸（Regression）**：預測連續值（如房價）。

**簡單範例**：  
假設你有一個數據集，包含房屋的面積、房間數量和價格（標籤）。使用線性回歸模型進行監督式學習，模型學習面積和房間數量與價格之間的關係。訓練後，模型可以根據新房屋的面積和房間數量預測其價格。例如：
- 輸入：面積 = 100 平方米，房間數 = 2
- 標籤：價格 = 500 萬
- 模型預測新房屋的價格，實現回歸任務。

**常見算法**：
- 線性回歸（Linear Regression）
- 邏輯回歸（Logistic Regression）
- 支援向量機（Support Vector Machine, SVM）
- 決策樹（Decision Tree）
- 神經網絡（Neural Networks）

---

### 2. 非監督式學習（Unsupervised Learning）
**描述**：  
非監督式學習是指在沒有標籤的數據上進行訓練，模型通過發現數據中的內在結構、模式或關係來學習。非監督式學習的目標是探索數據的隱含分佈或分組，而非預測特定輸出。

**特徵**：
- 數據僅包含輸入特徵 \( X \)，無對應標籤 \( y \)。
- 主要任務包括：
  - **聚類（Clustering）**：將數據分為相似的群組（如客戶分群）。
  - **降維（Dimensionality Reduction）**：將高維數據簡化為低維表示（如主成分分析）。
- 模型學習數據的分佈或結構，而非直接預測。

**簡單範例**：  
假設你有一個包含客戶購買行為的數據集（例如購買的產品類型和頻率），但沒有標籤。使用 K 均值聚類（K-means Clustering）算法進行非監督式學習，模型將客戶分為若干群組（如高消費群、低消費群）。例如：
- 輸入：客戶 A 的購買記錄（10 次購買電子產品，5 次購買服裝）
- 模型輸出：客戶 A 屬於“科技愛好者”群組。
- 這種分組有助於市場營銷策略的制定。

**常見算法**：
- K 均值聚類（K-means Clustering）
- 層次聚類（Hierarchical Clustering）
- 主成分分析（PCA, Principal Component Analysis）
- 自編碼器（Autoencoders）
- 關聯規則挖掘（Association Rule Mining）



### 總結與比較
- **監督式學習**：
  - 需要標籤數據。
  - 目標是預測（如分類或回歸）。
  - 範例：根據歷史房價數據預測新房屋價格。
- **非監督式學習**：
  - 無標籤數據。
  - 目標是發現數據模式（如聚類或降維）。
  - 範例：根據購買行為將客戶分群。
- **關鍵區別**：監督式學習依賴`標籤`來指導學習，非監督式學習則依賴`數據本身的結構`。

**實際應用**：
- 監督式學習：垃圾郵件過濾、信用風險評估、醫療診斷。
- 非監督式學習：市場細分、異常檢測、圖像壓縮。

---

## 模型的**參數**和**超參數**


在機器學習中，**參數（Parameters）**與**超參數（Hyperparameters）**是模型訓練與優化過程中兩個非常重要但本質不同的概念。以下針對兩者進行說明與比較：

### 1. 參數（Parameters）
**描述**：  
參數是指模型在訓練過程中自動學習得到的變數，最常見的例子是神經網路中的權重（weights）和偏差（biases）。這些參數會根據訓練數據不斷調整，最終使模型能夠擬合數據、進行預測。

**特徵**：
- 參數由模型自動學習獲得，無需人工設定。
- 參數的數值會隨著訓練過程不斷更新。
- 直接影響模型對數據的擬合能力。
- 例如：線性回歸中的斜率與截距、神經網路中的權重矩陣。

### 2. 超參數（Hyperparameters）
**描述**：  
超參數是指在訓練模型之前需要由使用者手動設定的參數，這些參數不會在訓練過程中自動調整，而是影響模型訓練的方式與效果。

**特徵**：
- 超參數必須在訓練前指定，無法由模型自動學習。
- 影響模型的結構、訓練過程或學習速率等。
- 常見超參數包括：學習率（learning rate）、決策樹的深度、神經網路的層數、每批訓練資料的大小（batch size）、正則化係數等。
- 選擇合適的超參數對模型表現有關鍵影響，通常需透過驗證集或交叉驗證來調整。

### 3. 參數與超參數的區別
| 分類     | 參數（Parameters）         | 超參數（Hyperparameters）         |
|----------|---------------------------|-----------------------------------|
| 調整方式 | 由模型自動學習            | 需人工設定，訓練前決定            |
| 作用     | 決定模型對數據的擬合能力  | 影響模型訓練過程與結構            |
| 例子     | 權重、偏差                | 學習率、層數、正則化係數等        |

**簡單總結**：  
- 參數是模型「學」出來的，超參數是你「設定」的。
- 調整超參數通常需要多次實驗與驗證，找到最佳組合後再進行模型訓練。

> 💡 **小提醒**：  
> 若你發現模型表現不佳，除了檢查資料品質與特徵工程外，也要考慮是否需要調整超參數！


---

## 數據的**特徵**和**標籤**
在機器學習中，特別是監督式學習中，數據集通常由**特徵**（Features）和**標籤**（Labels）組成



### 1. 特徵（Features）
**描述**：  
特徵是數據集中用來描述每個數據點的屬性或變量，通常表示為輸入變量 \( X \)。特徵是模型用來學習和進行預測的基礎，代表數據的特性或模式。特徵可以是數值型（如年齡、面積）、類別型（如性別、顏色）或其他形式。

**特徵**：
- 特徵是數據的獨立變量，模型通過分析特徵來學習與標籤的關係。
- 特徵選擇與特徵工程（Feature Engineering）能顯著影響模型的學習效果與`預測準確度`。
- 特徵通常需要經過適當的預處理（如標準化、正規化），以確保模型能更有效地學習數據中的`規律`。



### 2. 標籤（Labels）
**描述**：  
標籤是數據集中每個數據點的目標輸出或結果，通常表示為 \( y \)。在監督式學習中，標籤是模型需要預測的變量，代表數據的真實答案或類別。標籤可以是連續值（回歸問題）或離散類別（分類問題）。

**特徵**：
- 標籤是監督式學習的指導信號，模型通過比較預測值與真實標籤來優化。
- 標籤由數據收集者提供，通常需要`人工標註`。
- 非監督式學習中無標籤，僅有特徵。



### 簡單範例
假設你正在構建一個機器學習模型來預測房價（監督式學習中的回歸問題）。數據集可能如下：

| 房屋編號 | 面積（平方米） | 房間數 | 位置 | 價格（萬） |
|----------|----------------|--------|------|------------|
| 1        | 100            | 2      | 市中心 | 500        |
| 2        | 80             | 1      | 郊區   | 300        |
| 3        | 120            | 3      | 市中心 | 600        |

**特徵**：
- 面積（數值型特徵）
- 房間數（數值型特徵）
- 位置（類別型特徵）

**標籤**：
- 價格（連續值，作為回歸問題的目標）

**說明**：
- 在這個例子中，模型使用特徵（面積、房間數、位置）來學習與標籤（價格）之間的關係。訓練後，模型可以根據新房屋的特徵（例如面積 = 90 平方米，房間數 = 2，位置 = 郊區）預測其價格。
- 特徵是輸入，幫助模型理解房屋的特性；標籤是輸出，告訴模型真實的房價。

**另一個分類問題範例**：
假設你要預測電子郵件是否為垃圾郵件：
- **特徵**：郵件長度、發件人域名、關鍵詞頻率（如“免費”出現次數）。
- **標籤**：是否為垃圾郵件（是/否，類別型）。



### 總結
- **特徵**：數據的輸入變量，描述數據點的屬性，用於模型學習。
- **標籤**：數據的目標輸出，僅在監督式學習中使用，指導模型預測。
- **關係**：模型通過學習特徵與標籤之間的映射關係，實現預測或分類任務。

---

## **訓練集**和**測試集**

在機器學習中，特別是監督式學習中，數據集通常被分割為**訓練集**（Training Set）和**測試集**（Test Set），以`評估`模型的性能並確保其泛化能力。



### 1. 訓練集（Training Set）
**描述**：  
訓練集是數據集的一部分，用於訓練機器學習模型。模型通過分析訓練集中的特徵和標籤，學習輸入與輸出之間的關係。訓練集通常占數據集的較大比例，以確保模型有足夠的數據來學習模式。

**特徵**：
- 包含特徵 \( X \) 和標籤 \( y \)。
- 用於優化模型參數，使模型在訓練數據上最小化預測誤差。
- 訓練集的`質量`和`數量`直接影響模型的學習效果。



### 2. 測試集（Test Set）
**描述**：  
測試集是數據集的另一部分，用於評估訓練好的模型在`未見數據`上的性能。測試集與訓練集獨立，模型在訓練過程中不會接觸測試集數據，以模擬模型在現實世界中的泛化能力。

**特徵**：
- 同樣包含特徵 \( X \) 和標籤 \( y \)，但僅用於評估，而非訓練。
- 用於計算模型的泛化誤差，檢驗是否發生欠擬合或過度擬合。
- 測試集的獨立性確保評估結果客觀反映模型的真實性能。



### 分割的目的
- **訓練集**：讓模型學習數據中的模式和關係。
- **測試集**：驗證模型對新數據的預測能力，評估其泛化性能。
- **避免過擬合**：如果模型僅在訓練集上表現良好，但在測試集上誤差高，則表明`模型過擬合`，無法泛化到新數據。

**常見分割比例**：
- 訓練集：測試集 = 70:30、80:20 或 90:10，具體取決於數據量和`問題需求`。
- 有時還會使用**驗證集**（Validation Set）來調整模型超參數，通常從訓練集中再分割出一部分。
  - 例如：假設你有 100 筆數據，先分成 80 筆訓練集和 20 筆測試集，然後再從 80 筆訓練集中分出 10 筆作為驗證集（剩下 70 筆繼續當訓練集）。這 10 筆驗證集用來測試不同模型參數的效果，幫助你選出最佳參數組合，最後再用測試集評估最終模型的表現。



### 簡單範例
假設你有一個包含 100 條房屋數據的數據集，用於預測房價。每條數據包括特徵（面積、房間數）和標籤（價格）。你將數據集分割為訓練集和測試集：

- **數據分割**：
  - 訓練集：80 條數據（80%）
  - 測試集：20 條數據（20%）

- **數據示例**：

| 房屋編號 | 面積（平方米） | 房間數 | 價格（萬） | 數據集類型 |
|----------|----------------|--------|------------|------------|
| 1        | 100            | 2      | 500        | 訓練集     |
| 2        | 80             | 1      | 300        | 訓練集     |
| 3        | 120            | 3      | 600        | 測試集     |
| ...      | ...            | ...    | ...        | ...        |

**流程**：
1. **訓練階段**：使用訓練集（80 條數據）訓練線性回歸模型，模型學習面積、房間數與價格的關係。
2. **測試階段**：使用測試集（20 條數據）評估模型。輸入測試集的特徵（面積、房間數），比較模型預測的價格與真實價格，計算誤差（如均方誤差）。
3. **結果分析**：
   - 如果訓練集誤差低且測試集誤差也低，模型泛化良好。
   - 如果訓練集誤差低但測試集誤差高，模型可能過擬合。

**實際應用**：
- 在垃圾郵件分類任務中，訓練集用於學習郵件特徵（如關鍵詞頻率）與標籤（垃圾/非垃圾）的關係，測試集用於檢查模型是否能正確分類新郵件。



### 總結
- **訓練集**：用於模型學習，包含大部分數據，幫助模型擬合特徵與標籤的關係。
- **測試集**：用於評估模型性能，獨立於訓練集，檢驗模型的泛化能力。
- **分割原則**：確保訓練集和測試集數據分佈一致，隨機分割以避免偏差。

---

## 過度擬合（Overfitting）和 欠擬合（Underfitting）
機器學習中，欠擬合（underfitting）和過度擬合（overfitting）是模型性能不佳的兩種常見問題。

### 1. 欠擬合（Underfitting）
**描述**：  
欠擬合指模型過於簡單，無法捕捉訓練數據中的模式或規律，導致在訓練數據和測試數據上均表現不佳。這種情況通常因模型複雜度不足、特徵選擇不當或訓練時間不足引起。

**特徵**：
- 訓練誤差高
- 測試誤差高
- 模型無法有效學習數據的潛在關係

**簡單範例**：  
假設要用一條直線（線性回歸）擬合一個非線性關係的數據集，例如 \( y = x^2 \)。由於直線無法捕捉二次曲線的模式，模型在訓練和測試數據上的預測誤差都很大，這就是欠擬合。



### 2. 過度擬合（Overfitting）
**描述**：  
過度擬合指模型過於複雜，過分學習訓練數據中的細節和噪聲，導致在訓練數據上表現極佳，但在未見的測試數據上泛化能力差。這種情況通常因模型參數過多、數據量不足或缺乏正則化引起。

**特徵**：
- 訓練誤差低
- 測試誤差高
- 模型對訓練數據的細微變化過於敏感

**簡單範例**：  
假設用一個高階多項式（例如 10 次多項式）擬合包含少量噪聲的數據點 \( y = x + \text{噪聲} \)。模型可能生成一條通過所有訓練點的複雜曲線，但當應用於新數據時，預測結果偏差很大，因為它學會了噪聲而非真實的線性關係，這就是過度擬合。



### 總結與解決方案
- **欠擬合解決方案**：增加模型複雜度（例如使用更高層次的多項式或更深的深度學習神經網絡）、添加更多特徵、增加訓練時間。
- **過度擬合解決方案**：減少模型複雜度、增加訓練數據量、使用正則化技術（例如 L1/L2 正則化、丟棄法（Dropout）、提前停止（early stopping）、數據增強。

---

### 模型的泛化（Generalization）

**描述**：  
泛化是指機器學習模型在未見過的數據（測試數據或現實世界數據）上表現出良好預測能力的能力。換言之，模型不僅能有效擬合訓練數據，還能對新的、獨立的數據點進行準確預測。泛化是機器學習的核心目標，因為它反映了模型是否真正學會了數據的潛在模式，而非僅記憶訓練數據。

**特徵**：
- 模型在訓練數據和測試數據上的誤差相對接近且均較低。
- 模型能夠處理數據中的變異性（如噪聲或分布變化）並保持穩健的預測能力。
- 良好的泛化意味著模型避免了欠擬合（underfitting）和過度擬合（overfitting）。

**簡單範例**：  
假設你訓練一個模型來預測房價，基於房間數量和面積的數據。訓練數據包含 100 個房屋的價格信息，模型學會了房間數量和面積與價格之間的關係。如果這個模型在新數據（例如另一組 50 個房屋）上也能準確預測價格，且誤差與訓練數據上的誤差相近，則該模型具有良好的泛化能力。

**對比欠擬合與過度擬合**：
- **欠擬合**：模型過於簡單，無法學會訓練數據的模式，導致訓練和測試誤差均高，泛化能力差。
- **過度擬合**：模型過於複雜，過分擬合訓練數據的細節和噪聲，導致訓練誤差低但測試誤差高，泛化能力差。
- **良好泛化**：模型在訓練和測試數據上均表現良好，誤差低且穩定，能有效應對新數據。

**實現良好泛化的方法**：
- **適當的模型複雜度**：選擇與數據量和問題複雜度匹配的模型，例如避免使用過於複雜的深度神經網絡來處理簡單問題。
- **充足的數據**：更多的訓練數據有助於模型學習更廣泛的模式，減少過擬合風險。
- **正則化技術**：如 L1/L2 正則化、丟棄法（Dropout）或數據增強，防止模型過分依賴訓練數據的特定特徵。
- **交叉驗證**：使用 k 折交叉驗證來評估模型在不同數據子集上的性能，確保泛化能力。
- **提前停止**：在訓練過程中監控驗證集誤差，當驗證誤差不再下降時停止訓練，以避免過度擬合。

**總結**：  
泛化是機器學習模型成功應用於現實世界的關鍵，代表模型從訓練數據中學到的知識能夠有效應用於新數據。通過平衡模型複雜度、數據量和正則化技術，可以提高模型的泛化能力，從而實現穩健的預測性能。


### ML的整個「訓練過程」：這裡以監督式學習(Supervised Learning)為例

| **階段**   | **要做的事**  | **說明**                                  |
| ----------- | --------- | --------------------------------------- |
| 1. (訓練前)  | 決定資料集與分析資料      | 你想要預測的是什麼資料? 這邊需要先知道 example、label、features的概念。 |
| 2. (訓練前) | 決定問題種類   | 依據資料，會知道是什麼類型的問題。regression problem(回歸問題)? classification problem(分類問題)?          |
| 3. (訓練前)  | 決定ML模型(ML models)     | 依據問題的種類，會知道需要使用什麼對應的ML模型。回歸模型(Regression model)? 分類模型(Classification model)? |
| 4. (訓練前) | (模型裡面的參數)     | ML模型裡面的參數(parameters)與超參數(hyper-parameters)   |
| 5. (訓練中) 調整模型  | 評估當前模型好壞    | 損失函數(Loss Functions)：使用損失函數評估目前模型的好與壞。以MSE(Mean Squared Error), RMSE(Root Mean Squared Error), 交叉熵(Cross Entropy)為例。 |
| (訓練中) 調整模型  | 修正模型參數    | 以梯度下降法 (Gradient Descent)為例：決定模型中參數的修正「方向」與「步長(step size)」 |
| 7. (訓練中) 調整腳步 | 調整學習腳步 | 透過學習速率(learning rate)來調整ML模型訓練的步長(step size)，調整學習腳步。|
| 8. (訓練中) 加快訓練 | 取樣與分堆 | 設定batch size，透過batch從訓練目標中取樣，來加快ML模型訓練的速度。(此參數在訓練前設定，為hyper-parameter)。與迭代(iteration),epoch介紹。 |
| 9. ((訓練中) 完成訓練 | (loop) -> 完成 | 重覆過程(評估當前模型好壞 -> 修正模型參數)，直到能通過「驗證資料集(Validation)」的驗證即可結束訓練。 |
| 10. (訓練後) | 訓練結果可能問題 | 「不適當的最小loss?」 |
| 11. (訓練後) | 訓練結果可能問題 | 欠擬合(underfitting)?過度擬合(overfitting)?  |
| 12. (訓練後) | 評估 - 性能指標 | 性能指標(performance metrics)：以混淆矩陣(confusion matrix)分析，包含「Accuracy」、「Precision」、「Recall」三種評估指標。  |
| 13. (訓練後) | 評估 - 新資料適用性 | 泛化(Generalization)：對於新資料、沒看過的資料的模型適用性。 |
| 14. (訓練後) | 評估 - 模型測試 | 使用「獨立測試資料集(Test)」測試. 使用交叉驗證(cross-validation)(又稱bootstrapping)測試. |

### 泛化(generalize)：指ML模型「對未知資料集」的預測能力。

> 泛化(generalize)能力差：等於預測「對未知資料集」的預測能力能力差。  
> 但如果對「對自己的資料」的預測能力很好，有可能是發生了過度擬合(overfitting)的現象。

### ★ 欠擬合(underfitting) 與 過度擬合(overfitting)


| **比較**   | **‌欠擬合(underfitting)**  | **過度擬合(overfitting)** |
| ----------- | --------- | --------------------------------------- |
| (訓練前) | (可能)決定了太簡單的模型 | (可能)決定了太複雜的模型 |
| (訓練中) | (可能)訓練太早結束 | (可能)訓練過頭，也就是太晚結束 |
| (訓練後)對自已的資料 | 訓練後發現模型「對自已的資料」預測能力太差 | 訓練後發現模型「對自已的資料」預測能力非常好(可能好到沒有誤差) |
| (訓練後)對新的資料 | (對自己的資料都不行了還要試新資料嗎XD) | 訓練後發現模型「對新的資料」預測能力非常差 |
| 代表的意義 | 我們的模型「對自已的資料」沒辦法達到理想的預測能力 | 我們的模型「對新的資料」沒辦法達到理想的預測能力，然而對「對自已的資料」預測能力非常好。 |

> [!TIP]
> 「最佳的ML模型訓練結果」應該介於欠擬合(underfitting) 與 過度擬合(overfitting)之間。

#### 用圖簡單解釋 欠擬合(underfitting) 與 過度擬合(overfitting)

使用Matplotlib 來展示欠擬合 (underfitting) 和過度擬合 (overfitting) 的概念，並搭配簡單的例子來說明這兩個現象在機器學習中的區別。

假設我們有一個簡單的非線性數據集，並嘗試用不同複雜度的模型來擬合它：

[**實作的ipynb**](./README.ipynb)

![](./images/pic1.png)




### 擬合模型：
- **欠擬合**：用一次多項式（直線）擬合，無法捕捉數據的非線性趨勢。
- **適當擬合**：用二次多項式（拋物線）擬合，與真實數據的趨勢匹配。
- **過度擬合**：用 10 次多項式擬合，過分捕捉噪聲，導致曲線過於複雜。

---

## 評估指標 (Performance Metrics)

在機器學習中，評估指標是用來衡量模型性能的重要工具。不同的任務類型需要不同的評估指標。

### 分類指標

#### 混淆矩陣 (Confusion Matrix)
**描述**：  
混淆矩陣是一個表格，用於總結分類模型的預測結果，顯示真正例(TP)、真負例(TN)、假正例(FP)、假負例(FN)的數量。

**用途**：
- 提供詳細的分類錯誤和正確預測分析
- 是計算其他指標的基礎
- 在多類別問題中揭示哪些類別容易被混淆

**關鍵術語**：
- **真正例 (True Positive, TP)**：模型正確預測為正類的樣本
- **真負例 (True Negative, TN)**：模型正確預測為負類的樣本
- **假正例 (False Positive, FP)**：模型錯誤地預測為正類的樣本
- **假負例 (False Negative, FN)**：模型錯誤地預測為負類的樣本

#### 準確率 (Accuracy)
**描述**：  
正確分類的樣本數佔總樣本數的比例。

**公式**：`Accuracy = (TP + TN) / (TP + TN + FP + FN)`

**適用場景**：
- 類別分佈均衡的數據集
- 需要整體正確性的評估

**限制**：在不均衡數據集中可能具有誤導性

#### 精確率 (Precision)
**描述**：  
在所有預測為正類的樣本中，實際為正類的比例。

**公式**：`Precision = TP / (TP + FP)`

**適用場景**：
- 假正例代價較高的場景（如醫療診斷）
- 需要確保預測結果的可靠性

#### 召回率 (Recall)
**描述**：  
在所有實際為正類的樣本中，被正確預測為正類的比例。

**公式**：`Recall = TP / (TP + FN)`

**適用場景**：
- 假負例代價較高的場景（如癌症篩查）
- 需要確保不漏掉重要的正例

#### F1分數 (F1-Score)
**描述**：  
精確率和召回率的調和平均數，提供平衡兩者的單一指標。

**公式**：`F1-score = 2 * (Precision * Recall) / (Precision + Recall)`

**適用場景**：
- 需要平衡精確率和召回率
- 當假正例和假負例均重要時

### 回歸指標

#### 均方誤差 (MSE)
**描述**：  
預測值與實際值之間差的平方的平均值。

**公式**：`MSE = (1/n) * Σ(y實際 - y預測)²`

**特點**：
- 通過平方放大較大的誤差
- 結果越小代表模型預測越準確

#### 均方根誤差 (RMSE)
**描述**：  
均方誤差的平方根。

**公式**：`RMSE = √MSE`

**特點**：
- 單位與原始數據相同，更容易解釋
- 更容易理解預測誤差的實際意義

#### 平均絕對誤差 (MAE)
**描述**：  
預測值與實際值之間絕對誤差的平均值。

**公式**：`MAE = (1/n) * Σ|y實際 - y預測|`

**特點**：
- 對異常值不敏感
- 結果容易理解

#### R²分數 (R-Squared)
**描述**：  
衡量模型解釋數據變異性的比例。

**公式**：`R² = 1 - (SS_res / SS_tot)`

**數值意義**：
- R² = 1：完美預測
- R² = 0：模型預測效果與平均值相同
- R² < 0：模型預測效果比平均值還差

---

## 特徵工程 (Feature Engineering)

特徵工程是利用領域知識來建立特徵，讓機器學習演算法得以運作的過程。它包含了特徵的創造、轉換、提取和選擇。

### 特徵選擇 (Feature Selection)
**描述**：  
從原始特徵中選擇最相關、最重要的特徵來訓練模型。

**方法**：
- **過濾法 (Filter Methods)**：基於統計指標選擇特徵
- **包裝法 (Wrapper Methods)**：使用模型性能來選擇特徵
- **嵌入法 (Embedded Methods)**：在模型訓練過程中選擇特徵

### 特徵縮放 (Feature Scaling)
**描述**：  
將不同特徵的數值範圍調整到相似的尺度，以提高模型性能。

#### 標準化 (Standardization)
**描述**：  
將數據轉換為平均值為0，標準差為1的分佈。

**公式**：`z = (x - μ) / σ`

**適用算法**：
- 線性回歸
- 邏輯回歸
- 支援向量機
- 主成分分析

#### 正規化 (Normalization)
**描述**：  
將數據縮放到指定的範圍，通常是[0, 1]。

**公式**：`x_scaled = (x - x_min) / (x_max - x_min)`

**適用算法**：
- 類神經網路
- K-近鄰演算法

### 編碼方式

#### 標籤編碼 (Label Encoding)
**描述**：  
將文字類別轉換為數值標籤。

**適用場景**：有序類別特徵

**範例**：
- 小、中、大 → 0、1、2

#### 獨熱編碼 (One-Hot Encoding)
**描述**：  
將類別變量轉換為二進制向量。

**適用場景**：無序類別特徵

**範例**：
- 紅色、綠色、藍色 → [1,0,0]、[0,1,0]、[0,0,1]

---

## 優化算法 (Optimization)

### 梯度下降法 (Gradient Descent)
**描述**：  
一種優化算法，通過計算損失函數的梯度來更新模型參數。

**運作原理**：
1. 計算損失函數對參數的梯度
2. 沿著梯度相反方向更新參數
3. 重複直到收斂

**公式**：`θ = θ - α * ∇J(θ)`

**類型**：
- **批次梯度下降**：使用全部訓練數據
- **隨機梯度下降**：使用單一樣本
- **小批次梯度下降**：使用小批次數據

### 學習率 (Learning Rate)
**描述**：  
控制參數更新步長的超參數。

**影響**：
- 學習率過大：可能跳過最優解
- 學習率過小：收斂速度慢

**選擇策略**：
- 從較大值開始，逐漸減小
- 使用學習率調度器

### 批次大小 (Batch Size)
**描述**：  
每次迭代中使用的訓練樣本數量。

**影響**：
- 批次大小大：訓練穩定但記憶體需求高
- 批次大小小：訓練不穩定但記憶體需求低

**常見選擇**：32、64、128、256

---

## 常見算法 (Common Algorithms)

### K-近鄰 (K-NN)
**描述**：  
基於距離的分類算法，根據最近的K個鄰居來進行預測。

**特點**：
- 簡單直觀，容易理解
- 對多種類別分類效果不錯
- 計算量可能較大
- 容易受到資料雜訊的影響

**關鍵參數**：
- **k值**：選擇的鄰居數量
- **距離度量**：歐氏距離、曼哈頓距離等

### 決策樹 (Decision Tree)
**描述**：  
基於樹狀結構的分類和回歸算法。

**特點**：
- 容易理解和解釋
- 可以處理非線性關係
- 不需要特徵縮放
- 容易過擬合

**關鍵參數**：
- **最大深度**：控制樹的複雜度
- **最小樣本分割**：防止過擬合

### 支援向量機 (SVM)
**描述**：  
尋找最大間隔超平面的分類算法。

**特點**：
- 可以處理非線性分類問題（通過核技巧）
- 對異常值具有較強的魯棒性
- 適合高維數據
- 記憶體需求較大

**關鍵參數**：
- **C參數**：控制正則化強度
- **核函數**：線性、多項式、RBF等

### 樸素貝氏 (Naive Bayes)
**描述**：  
基於貝氏定理的分類算法，假設特徵之間相互獨立。

**類型**：
- **GaussianNB**：適用連續數據
- **BernoulliNB**：適用二元數據
- **MultinomialNB**：適用計數數據

**特點**：
- 訓練速度快
- 適合小數據集
- 對缺失數據不敏感

---

## 集成學習 (Ensemble Learning)

集成學習是將多個基礎學習器組合起來，以獲得比單一學習器更好的預測性能的方法。

### Bagging (Bootstrap Aggregating)
**描述**：  
通過並行訓練多個模型並平均其預測結果來提高性能。

**代表算法**：隨機森林 (Random Forest)

**特點**：
- 減少過擬合
- 提高模型穩定性
- 可以並行訓練

**運作方式**：
1. 從原始數據集中有放回地抽取多個子集
2. 在每個子集上訓練一個基礎模型
3. 對預測結果進行平均或投票

### Boosting
**描述**：  
通過順序訓練多個模型，每個模型專注於前一個模型的錯誤來提高性能。

**代表算法**：梯度提升 (Gradient Boosting)

**特點**：
- 逐步改善模型性能
- 可以處理複雜的非線性關係
- 訓練時間較長

**運作方式**：
1. 訓練第一個基礎模型
2. 計算預測誤差
3. 訓練下一個模型來修正誤差
4. 重複直到達到預設的模型數量

### Stacking
**描述**：  
使用一個元學習器來組合多個基礎模型的預測結果。

**特點**：
- 可以組合不同類型的模型
- 通常能獲得更好的性能
- 計算複雜度較高

**運作方式**：
1. 訓練多個不同的基礎模型
2. 使用基礎模型的預測作為特徵
3. 訓練元學習器來組合這些預測

