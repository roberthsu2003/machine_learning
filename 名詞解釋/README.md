## 監督式學習（Supervised Learning）和 非監督式學習（Unsupervised Learning）

在機器學習中，監督式學習（Supervised Learning）和非監督式學習（Unsupervised Learning）是兩種主要的學習範式。

---

### 1. 監督式學習（Supervised Learning）
**描述**：  
監督式學習是指使用帶有標籤（即已知輸出或目標變量）的訓練數據來訓練模型。模型通過學習輸入特徵與對應標籤之間的關係，來預測新數據的輸出。監督式學習的目標是讓模型能夠對未見數據進行準確預測或分類。

**特徵**：
- 數據包含輸入特徵 \( X \) 和對應的標籤 \( y \)。
- 訓練目標是最小化預測值與真實標籤之間的誤差。
- 主要任務包括：
  - **分類（Classification）**：預測離散類別（如垃圾郵件或非垃圾郵件）。
  - **回歸（Regression）**：預測連續值（如房價）。

**簡單範例**：  
假設你有一個數據集，包含房屋的面積、房間數量和價格（標籤）。使用線性回歸模型進行監督式學習，模型學習面積和房間數量與價格之間的關係。訓練後，模型可以根據新房屋的面積和房間數量預測其價格。例如：
- 輸入：面積 = 100 平方米，房間數 = 2
- 標籤：價格 = 500 萬
- 模型預測新房屋的價格，實現回歸任務。

**常見算法**：
- 線性回歸（Linear Regression）
- 邏輯回歸（Logistic Regression）
- 支援向量機（Support Vector Machine, SVM）
- 決策樹（Decision Tree）
- 神經網絡（Neural Networks）

---

### 2. 非監督式學習（Unsupervised Learning）
**描述**：  
非監督式學習是指在沒有標籤的數據上進行訓練，模型通過發現數據中的內在結構、模式或關係來學習。非監督式學習的目標是探索數據的隱含分佈或分組，而非預測特定輸出。

**特徵**：
- 數據僅包含輸入特徵 \( X \)，無對應標籤 \( y \)。
- 主要任務包括：
  - **聚類（Clustering）**：將數據分為相似的群組（如客戶分群）。
  - **降維（Dimensionality Reduction）**：將高維數據簡化為低維表示（如主成分分析）。
- 模型學習數據的分佈或結構，而非直接預測。

**簡單範例**：  
假設你有一個包含客戶購買行為的數據集（例如購買的產品類型和頻率），但沒有標籤。使用 K 均值聚類（K-means Clustering）算法進行非監督式學習，模型將客戶分為若干群組（如高消費群、低消費群）。例如：
- 輸入：客戶 A 的購買記錄（10 次購買電子產品，5 次購買服裝）
- 模型輸出：客戶 A 屬於“科技愛好者”群組。
- 這種分組有助於市場營銷策略的制定。

**常見算法**：
- K 均值聚類（K-means Clustering）
- 層次聚類（Hierarchical Clustering）
- 主成分分析（PCA, Principal Component Analysis）
- 自編碼器（Autoencoders）
- 關聯規則挖掘（Association Rule Mining）

---

### 總結與比較
- **監督式學習**：
  - 需要標籤數據。
  - 目標是預測（如分類或回歸）。
  - 範例：根據歷史房價數據預測新房屋價格。
- **非監督式學習**：
  - 無標籤數據。
  - 目標是發現數據模式（如聚類或降維）。
  - 範例：根據購買行為將客戶分群。
- **關鍵區別**：監督式學習依賴標籤來指導學習，非監督式學習則依賴數據本身的結構。

**實際應用**：
- 監督式學習：垃圾郵件過濾、信用風險評估、醫療診斷。
- 非監督式學習：市場細分、異常檢測、圖像壓縮。

---

## 過度擬合（Overfitting）和 欠擬合（Underfitting）
機器學習中，欠擬合（underfitting）和過度擬合（overfitting）是模型性能不佳的兩種常見問題。

### 1. 欠擬合（Underfitting）
**描述**：  
欠擬合指模型過於簡單，無法捕捉訓練數據中的模式或規律，導致在訓練數據和測試數據上均表現不佳。這種情況通常因模型複雜度不足、特徵選擇不當或訓練時間不足引起。

**特徵**：
- 訓練誤差高
- 測試誤差高
- 模型無法有效學習數據的潛在關係

**簡單範例**：  
假設要用一條直線（線性回歸）擬合一個非線性關係的數據集，例如 \( y = x^2 \)。由於直線無法捕捉二次曲線的模式，模型在訓練和測試數據上的預測誤差都很大，這就是欠擬合。

---

### 2. 過度擬合（Overfitting）
**描述**：  
過度擬合指模型過於複雜，過分學習訓練數據中的細節和噪聲，導致在訓練數據上表現極佳，但在未見的測試數據上泛化能力差。這種情況通常因模型參數過多、數據量不足或缺乏正則化引起。

**特徵**：
- 訓練誤差低
- 測試誤差高
- 模型對訓練數據的細微變化過於敏感

**簡單範例**：  
假設用一個高階多項式（例如 10 次多項式）擬合包含少量噪聲的數據點 \( y = x + \text{噪聲} \)。模型可能生成一條通過所有訓練點的複雜曲線，但當應用於新數據時，預測結果偏差很大，因為它學會了噪聲而非真實的線性關係，這就是過度擬合。

---

### 總結與解決方案
- **欠擬合解決方案**：增加模型複雜度（例如使用更高層次的多項式或更深的深度學習神經網絡）、添加更多特徵、增加訓練時間。
- **過度擬合解決方案**：減少模型複雜度、增加訓練數據量、使用正則化技術（例如 L1/L2 正則化、丟棄法（Dropout）、提前停止（early stopping）、數據增強。

---

### 模型的泛化（Generalization）

**描述**：  
泛化是指機器學習模型在未見過的數據（測試數據或現實世界數據）上表現出良好預測能力的能力。換言之，模型不僅能有效擬合訓練數據，還能對新的、獨立的數據點進行準確預測。泛化是機器學習的核心目標，因為它反映了模型是否真正學會了數據的潛在模式，而非僅記憶訓練數據。

**特徵**：
- 模型在訓練數據和測試數據上的誤差相對接近且均較低。
- 模型能夠處理數據中的變異性（如噪聲或分布變化）並保持穩健的預測能力。
- 良好的泛化意味著模型避免了欠擬合（underfitting）和過度擬合（overfitting）。

**簡單範例**：  
假設你訓練一個模型來預測房價，基於房間數量和面積的數據。訓練數據包含 100 個房屋的價格信息，模型學會了房間數量和面積與價格之間的關係。如果這個模型在新數據（例如另一組 50 個房屋）上也能準確預測價格，且誤差與訓練數據上的誤差相近，則該模型具有良好的泛化能力。

**對比欠擬合與過度擬合**：
- **欠擬合**：模型過於簡單，無法學會訓練數據的模式，導致訓練和測試誤差均高，泛化能力差。
- **過度擬合**：模型過於複雜，過分擬合訓練數據的細節和噪聲，導致訓練誤差低但測試誤差高，泛化能力差。
- **良好泛化**：模型在訓練和測試數據上均表現良好，誤差低且穩定，能有效應對新數據。

**實現良好泛化的方法**：
- **適當的模型複雜度**：選擇與數據量和問題複雜度匹配的模型，例如避免使用過於複雜的深度神經網絡來處理簡單問題。
- **充足的數據**：更多的訓練數據有助於模型學習更廣泛的模式，減少過擬合風險。
- **正則化技術**：如 L1/L2 正則化、丟棄法（Dropout）或數據增強，防止模型過分依賴訓練數據的特定特徵。
- **交叉驗證**：使用 k 折交叉驗證來評估模型在不同數據子集上的性能，確保泛化能力。
- **提前停止**：在訓練過程中監控驗證集誤差，當驗證誤差不再下降時停止訓練，以避免過度擬合。

**總結**：  
泛化是機器學習模型成功應用於現實世界的關鍵，代表模型從訓練數據中學到的知識能夠有效應用於新數據。通過平衡模型複雜度、數據量和正則化技術，可以提高模型的泛化能力，從而實現穩健的預測性能。


### ML的整個「訓練過程」：這裡以監督式學習(Supervised Learning)為例

| **階段**   | **要做的事**  | **說明**                                  |
| ----------- | --------- | --------------------------------------- |
| 1. (訓練前)  | 決定資料集與分析資料      | 你想要預測的是什麼資料? 這邊需要先知道 example、label、features的概念。 |
| 2. (訓練前) | 決定問題種類   | 依據資料，會知道是什麼類型的問題。regression problem(回歸問題)? classification problem(分類問題)?          |
| 3. (訓練前)  | 決定ML模型(ML models)     | 依據問題的種類，會知道需要使用什麼對應的ML模型。回歸模型(Regression model)? 分類模型(Classification model)? |
| 4. (訓練前) | (模型裡面的參數)     | ML模型裡面的參數(parameters)與超參數(hyper-parameters)   |
| 5. (訓練中) 調整模型  | 評估當前模型好壞    | 損失函數(Loss Functions)：使用損失函數評估目前模型的好與壞。以MSE(Mean Squared Error), RMSE(Root Mean Squared Error), 交叉熵(Cross Entropy)為例。 |
| (訓練中) 調整模型  | 修正模型參數    | 以梯度下降法 (Gradient Descent)為例：決定模型中參數的修正「方向」與「步長(step size)」 |
| 7. (訓練中) 調整腳步 | 調整學習腳步 | 透過學習速率(learning rate)來調整ML模型訓練的步長(step size)，調整學習腳步。|
| 8. (訓練中) 加快訓練 | 取樣與分堆 | 設定batch size，透過batch從訓練目標中取樣，來加快ML模型訓練的速度。(此參數在訓練前設定，為hyper-parameter)。與迭代(iteration),epoch介紹。 |
| 9. ((訓練中) 完成訓練 | (loop) -> 完成 | 重覆過程(評估當前模型好壞 -> 修正模型參數)，直到能通過「驗證資料集(Validation)」的驗證即可結束訓練。 |
| 10. (訓練後) | 訓練結果可能問題 | 「不適當的最小loss?」 |
| 11. (訓練後) | 訓練結果可能問題 | 欠擬合(underfitting)?過度擬合(overfitting)?  |
| 12. (訓練後) | 評估 - 性能指標 | 性能指標(performance metrics)：以混淆矩陣(confusion matrix)分析，包含「Accuracy」、「Precision」、「Recall」三種評估指標。  |
| 13. (訓練後) | 評估 - 新資料適用性 | 泛化(Generalization)：對於新資料、沒看過的資料的模型適用性。 |
| 14. (訓練後) | 評估 - 模型測試 | 使用「獨立測試資料集(Test)」測試. 使用交叉驗證(cross-validation)(又稱bootstrapping)測試. |

### 泛化(generalize)：指ML模型「對未知資料集」的預測能力。

> 泛化(generalize)能力差：等於預測「對未知資料集」的預測能力能力差。  
> 但如果對「對自己的資料」的預測能力很好，有可能是發生了過度擬合(overfitting)的現象。

### ★ 欠擬合(underfitting) 與 過度擬合(overfitting)


| **比較**   | **‌欠擬合(underfitting)**  | **過度擬合(overfitting)** |
| ----------- | --------- | --------------------------------------- |
| (訓練前) | (可能)決定了太簡單的模型 | (可能)決定了太複雜的模型 |
| (訓練中) | (可能)訓練太早結束 | (可能)訓練過頭，也就是太晚結束 |
| (訓練後)對自已的資料 | 訓練後發現模型「對自已的資料」預測能力太差 | 訓練後發現模型「對自已的資料」預測能力非常好(可能好到沒有誤差) |
| (訓練後)對新的資料 | (對自己的資料都不行了還要試新資料嗎XD) | 訓練後發現模型「對新的資料」預測能力非常差 |
| 代表的意義 | 我們的模型「對自已的資料」沒辦法達到理想的預測能力 | 我們的模型「對新的資料」沒辦法達到理想的預測能力，然而對「對自已的資料」預測能力非常好。 |

> [!TIP]
> 「最佳的ML模型訓練結果」應該介於欠擬合(underfitting) 與 過度擬合(overfitting)之間。

#### 用圖簡單解釋 欠擬合(underfitting) 與 過度擬合(overfitting)

使用Matplotlib 來展示欠擬合 (underfitting) 和過度擬合 (overfitting) 的概念，並搭配簡單的例子來說明這兩個現象在機器學習中的區別。

假設我們有一個簡單的非線性數據集，並嘗試用不同複雜度的模型來擬合它：

[**實作的ipynb**](./README.ipynb)

![](./images/pic1.png)




### 擬合模型：
- **欠擬合**：用一次多項式（直線）擬合，無法捕捉數據的非線性趨勢。
- **適當擬合**：用二次多項式（拋物線）擬合，與真實數據的趨勢匹配。
- **過度擬合**：用 10 次多項式擬合，過分捕捉噪聲，導致曲線過於複雜。

