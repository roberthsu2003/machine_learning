## 監督式學習（Supervised Learning）和 非監督式學習（Unsupervised Learning）

在機器學習中，監督式學習（Supervised Learning）和非監督式學習（Unsupervised Learning）是兩種主要的學習範式。

---

### 1. 監督式學習（Supervised Learning）
**描述**：  
監督式學習是指使用帶有標籤（即已知輸出或目標變量）的訓練數據來訓練模型。模型通過學習輸入特徵與對應標籤之間的關係，來預測新數據的輸出。監督式學習的目標是讓模型能夠對未見數據進行準確預測或分類。

**特徵**：
- 數據包含輸入特徵 \( X \) 和對應的標籤 \( y \)。
- 訓練目標是最小化預測值與真實標籤之間的誤差。
- 主要任務包括：
  - **分類（Classification）**：預測離散類別（如垃圾郵件或非垃圾郵件）。
  - **回歸（Regression）**：預測連續值（如房價）。

**簡單範例**：  
假設你有一個數據集，包含房屋的面積、房間數量和價格（標籤）。使用線性回歸模型進行監督式學習，模型學習面積和房間數量與價格之間的關係。訓練後，模型可以根據新房屋的面積和房間數量預測其價格。例如：
- 輸入：面積 = 100 平方米，房間數 = 2
- 標籤：價格 = 500 萬
- 模型預測新房屋的價格，實現回歸任務。

**常見算法**：
- 線性回歸（Linear Regression）
- 邏輯回歸（Logistic Regression）
- 支援向量機（Support Vector Machine, SVM）
- 決策樹（Decision Tree）
- 神經網絡（Neural Networks）

---

### 2. 非監督式學習（Unsupervised Learning）
**描述**：  
非監督式學習是指在沒有標籤的數據上進行訓練，模型通過發現數據中的內在結構、模式或關係來學習。非監督式學習的目標是探索數據的隱含分佈或分組，而非預測特定輸出。

**特徵**：
- 數據僅包含輸入特徵 \( X \)，無對應標籤 \( y \)。
- 主要任務包括：
  - **聚類（Clustering）**：將數據分為相似的群組（如客戶分群）。
  - **降維（Dimensionality Reduction）**：將高維數據簡化為低維表示（如主成分分析）。
- 模型學習數據的分佈或結構，而非直接預測。

**簡單範例**：  
假設你有一個包含客戶購買行為的數據集（例如購買的產品類型和頻率），但沒有標籤。使用 K 均值聚類（K-means Clustering）算法進行非監督式學習，模型將客戶分為若干群組（如高消費群、低消費群）。例如：
- 輸入：客戶 A 的購買記錄（10 次購買電子產品，5 次購買服裝）
- 模型輸出：客戶 A 屬於“科技愛好者”群組。
- 這種分組有助於市場營銷策略的制定。

**常見算法**：
- K 均值聚類（K-means Clustering）
- 層次聚類（Hierarchical Clustering）
- 主成分分析（PCA, Principal Component Analysis）
- 自編碼器（Autoencoders）
- 關聯規則挖掘（Association Rule Mining）

---

### 總結與比較
- **監督式學習**：
  - 需要標籤數據。
  - 目標是預測（如分類或回歸）。
  - 範例：根據歷史房價數據預測新房屋價格。
- **非監督式學習**：
  - 無標籤數據。
  - 目標是發現數據模式（如聚類或降維）。
  - 範例：根據購買行為將客戶分群。
- **關鍵區別**：監督式學習依賴標籤來指導學習，非監督式學習則依賴數據本身的結構。

**實際應用**：
- 監督式學習：垃圾郵件過濾、信用風險評估、醫療診斷。
- 非監督式學習：市場細分、異常檢測、圖像壓縮。

---

## 數據的**特徵**和**標籤**
在機器學習中，特別是監督式學習中，數據集通常由**特徵**（Features）和**標籤**（Labels）組成

---

### 1. 特徵（Features）
**描述**：  
特徵是數據集中用來描述每個數據點的屬性或變量，通常表示為輸入變量 \( X \)。特徵是模型用來學習和進行預測的基礎，代表數據的特性或模式。特徵可以是數值型（如年齡、面積）、類別型（如性別、顏色）或其他形式。

**特徵**：
- 特徵是數據的獨立變量，模型通過分析特徵來學習與標籤的關係。
- 特徵選擇和工程（Feature Engineering）對模型性能至關重要。
- 特徵需要經過預處理（如標準化、正規化）以提高模型效果。

---

### 2. 標籤（Labels）
**描述**：  
標籤是數據集中每個數據點的目標輸出或結果，通常表示為 \( y \)。在監督式學習中，標籤是模型需要預測的變量，代表數據的真實答案或類別。標籤可以是連續值（回歸問題）或離散類別（分類問題）。

**特徵**：
- 標籤是監督式學習的指導信號，模型通過比較預測值與真實標籤來優化。
- 標籤由數據收集者提供，通常需要人工標註。
- 非監督式學習中無標籤，僅有特徵。

---

### 簡單範例
假設你正在構建一個機器學習模型來預測房價（監督式學習中的回歸問題）。數據集可能如下：

| 房屋編號 | 面積（平方米） | 房間數 | 位置 | 價格（萬） |
|----------|----------------|--------|------|------------|
| 1        | 100            | 2      | 市中心 | 500        |
| 2        | 80             | 1      | 郊區   | 300        |
| 3        | 120            | 3      | 市中心 | 600        |

**特徵**：
- 面積（數值型特徵）
- 房間數（數值型特徵）
- 位置（類別型特徵）

**標籤**：
- 價格（連續值，作為回歸問題的目標）

**說明**：
- 在這個例子中，模型使用特徵（面積、房間數、位置）來學習與標籤（價格）之間的關係。訓練後，模型可以根據新房屋的特徵（例如面積 = 90 平方米，房間數 = 2，位置 = 郊區）預測其價格。
- 特徵是輸入，幫助模型理解房屋的特性；標籤是輸出，告訴模型真實的房價。

**另一個分類問題範例**：
假設你要預測電子郵件是否為垃圾郵件：
- **特徵**：郵件長度、發件人域名、關鍵詞頻率（如“免費”出現次數）。
- **標籤**：是否為垃圾郵件（是/否，類別型）。

---

### 總結
- **特徵**：數據的輸入變量，描述數據點的屬性，用於模型學習。
- **標籤**：數據的目標輸出，僅在監督式學習中使用，指導模型預測。
- **關係**：模型通過學習特徵與標籤之間的映射關係，實現預測或分類任務。

---

## **訓練集**和**測試集**

在機器學習中，特別是監督式學習中，數據集通常被分割為**訓練集**（Training Set）和**測試集**（Test Set），以評估模型的性能並確保其泛化能力。



### 1. 訓練集（Training Set）
**描述**：  
訓練集是數據集的一部分，用於訓練機器學習模型。模型通過分析訓練集中的特徵和標籤，學習輸入與輸出之間的關係。訓練集通常占數據集的較大比例，以確保模型有足夠的數據來學習模式。

**特徵**：
- 包含特徵 \( X \) 和標籤 \( y \)。
- 用於優化模型參數，使模型在訓練數據上最小化預測誤差。
- 訓練集的質量和數量直接影響模型的學習效果。



### 2. 測試集（Test Set）
**描述**：  
測試集是數據集的另一部分，用於評估訓練好的模型在未見數據上的性能。測試集與訓練集獨立，模型在訓練過程中不會接觸測試集數據，以模擬模型在現實世界中的泛化能力。

**特徵**：
- 同樣包含特徵 \( X \) 和標籤 \( y \)，但僅用於評估，而非訓練。
- 用於計算模型的泛化誤差，檢驗是否發生欠擬合或過度擬合。
- 測試集的獨立性確保評估結果客觀反映模型的真實性能。



### 分割的目的
- **訓練集**：讓模型學習數據中的模式和關係。
- **測試集**：驗證模型對新數據的預測能力，評估其泛化性能。
- **避免過擬合**：如果模型僅在訓練集上表現良好，但在測試集上誤差高，則表明模型過擬合，無法泛化到新數據。

**常見分割比例**：
- 訓練集：測試集 = 70:30、80:20 或 90:10，具體取決於數據量和問題需求。
- 有時還會使用**驗證集**（Validation Set）來調整模型超參數，通常從訓練集中再分割出一部分。



### 簡單範例
假設你有一個包含 100 條房屋數據的數據集，用於預測房價。每條數據包括特徵（面積、房間數）和標籤（價格）。你將數據集分割為訓練集和測試集：

- **數據分割**：
  - 訓練集：80 條數據（80%）
  - 測試集：20 條數據（20%）

- **數據示例**：

| 房屋編號 | 面積（平方米） | 房間數 | 價格（萬） | 數據集類型 |
|----------|----------------|--------|------------|------------|
| 1        | 100            | 2      | 500        | 訓練集     |
| 2        | 80             | 1      | 300        | 訓練集     |
| 3        | 120            | 3      | 600        | 測試集     |
| ...      | ...            | ...    | ...        | ...        |

**流程**：
1. **訓練階段**：使用訓練集（80 條數據）訓練線性回歸模型，模型學習面積、房間數與價格的關係。
2. **測試階段**：使用測試集（20 條數據）評估模型。輸入測試集的特徵（面積、房間數），比較模型預測的價格與真實價格，計算誤差（如均方誤差）。
3. **結果分析**：
   - 如果訓練集誤差低且測試集誤差也低，模型泛化良好。
   - 如果訓練集誤差低但測試集誤差高，模型可能過擬合。

**實際應用**：
- 在垃圾郵件分類任務中，訓練集用於學習郵件特徵（如關鍵詞頻率）與標籤（垃圾/非垃圾）的關係，測試集用於檢查模型是否能正確分類新郵件。

---

### 總結
- **訓練集**：用於模型學習，包含大部分數據，幫助模型擬合特徵與標籤的關係。
- **測試集**：用於評估模型性能，獨立於訓練集，檢驗模型的泛化能力。
- **分割原則**：確保訓練集和測試集數據分佈一致，隨機分割以避免偏差。

---

## 過度擬合（Overfitting）和 欠擬合（Underfitting）
機器學習中，欠擬合（underfitting）和過度擬合（overfitting）是模型性能不佳的兩種常見問題。

### 1. 欠擬合（Underfitting）
**描述**：  
欠擬合指模型過於簡單，無法捕捉訓練數據中的模式或規律，導致在訓練數據和測試數據上均表現不佳。這種情況通常因模型複雜度不足、特徵選擇不當或訓練時間不足引起。

**特徵**：
- 訓練誤差高
- 測試誤差高
- 模型無法有效學習數據的潛在關係

**簡單範例**：  
假設要用一條直線（線性回歸）擬合一個非線性關係的數據集，例如 \( y = x^2 \)。由於直線無法捕捉二次曲線的模式，模型在訓練和測試數據上的預測誤差都很大，這就是欠擬合。

---

### 2. 過度擬合（Overfitting）
**描述**：  
過度擬合指模型過於複雜，過分學習訓練數據中的細節和噪聲，導致在訓練數據上表現極佳，但在未見的測試數據上泛化能力差。這種情況通常因模型參數過多、數據量不足或缺乏正則化引起。

**特徵**：
- 訓練誤差低
- 測試誤差高
- 模型對訓練數據的細微變化過於敏感

**簡單範例**：  
假設用一個高階多項式（例如 10 次多項式）擬合包含少量噪聲的數據點 \( y = x + \text{噪聲} \)。模型可能生成一條通過所有訓練點的複雜曲線，但當應用於新數據時，預測結果偏差很大，因為它學會了噪聲而非真實的線性關係，這就是過度擬合。

---

### 總結與解決方案
- **欠擬合解決方案**：增加模型複雜度（例如使用更高層次的多項式或更深的深度學習神經網絡）、添加更多特徵、增加訓練時間。
- **過度擬合解決方案**：減少模型複雜度、增加訓練數據量、使用正則化技術（例如 L1/L2 正則化、丟棄法（Dropout）、提前停止（early stopping）、數據增強。

---

### 模型的泛化（Generalization）

**描述**：  
泛化是指機器學習模型在未見過的數據（測試數據或現實世界數據）上表現出良好預測能力的能力。換言之，模型不僅能有效擬合訓練數據，還能對新的、獨立的數據點進行準確預測。泛化是機器學習的核心目標，因為它反映了模型是否真正學會了數據的潛在模式，而非僅記憶訓練數據。

**特徵**：
- 模型在訓練數據和測試數據上的誤差相對接近且均較低。
- 模型能夠處理數據中的變異性（如噪聲或分布變化）並保持穩健的預測能力。
- 良好的泛化意味著模型避免了欠擬合（underfitting）和過度擬合（overfitting）。

**簡單範例**：  
假設你訓練一個模型來預測房價，基於房間數量和面積的數據。訓練數據包含 100 個房屋的價格信息，模型學會了房間數量和面積與價格之間的關係。如果這個模型在新數據（例如另一組 50 個房屋）上也能準確預測價格，且誤差與訓練數據上的誤差相近，則該模型具有良好的泛化能力。

**對比欠擬合與過度擬合**：
- **欠擬合**：模型過於簡單，無法學會訓練數據的模式，導致訓練和測試誤差均高，泛化能力差。
- **過度擬合**：模型過於複雜，過分擬合訓練數據的細節和噪聲，導致訓練誤差低但測試誤差高，泛化能力差。
- **良好泛化**：模型在訓練和測試數據上均表現良好，誤差低且穩定，能有效應對新數據。

**實現良好泛化的方法**：
- **適當的模型複雜度**：選擇與數據量和問題複雜度匹配的模型，例如避免使用過於複雜的深度神經網絡來處理簡單問題。
- **充足的數據**：更多的訓練數據有助於模型學習更廣泛的模式，減少過擬合風險。
- **正則化技術**：如 L1/L2 正則化、丟棄法（Dropout）或數據增強，防止模型過分依賴訓練數據的特定特徵。
- **交叉驗證**：使用 k 折交叉驗證來評估模型在不同數據子集上的性能，確保泛化能力。
- **提前停止**：在訓練過程中監控驗證集誤差，當驗證誤差不再下降時停止訓練，以避免過度擬合。

**總結**：  
泛化是機器學習模型成功應用於現實世界的關鍵，代表模型從訓練數據中學到的知識能夠有效應用於新數據。通過平衡模型複雜度、數據量和正則化技術，可以提高模型的泛化能力，從而實現穩健的預測性能。


### ML的整個「訓練過程」：這裡以監督式學習(Supervised Learning)為例

| **階段**   | **要做的事**  | **說明**                                  |
| ----------- | --------- | --------------------------------------- |
| 1. (訓練前)  | 決定資料集與分析資料      | 你想要預測的是什麼資料? 這邊需要先知道 example、label、features的概念。 |
| 2. (訓練前) | 決定問題種類   | 依據資料，會知道是什麼類型的問題。regression problem(回歸問題)? classification problem(分類問題)?          |
| 3. (訓練前)  | 決定ML模型(ML models)     | 依據問題的種類，會知道需要使用什麼對應的ML模型。回歸模型(Regression model)? 分類模型(Classification model)? |
| 4. (訓練前) | (模型裡面的參數)     | ML模型裡面的參數(parameters)與超參數(hyper-parameters)   |
| 5. (訓練中) 調整模型  | 評估當前模型好壞    | 損失函數(Loss Functions)：使用損失函數評估目前模型的好與壞。以MSE(Mean Squared Error), RMSE(Root Mean Squared Error), 交叉熵(Cross Entropy)為例。 |
| (訓練中) 調整模型  | 修正模型參數    | 以梯度下降法 (Gradient Descent)為例：決定模型中參數的修正「方向」與「步長(step size)」 |
| 7. (訓練中) 調整腳步 | 調整學習腳步 | 透過學習速率(learning rate)來調整ML模型訓練的步長(step size)，調整學習腳步。|
| 8. (訓練中) 加快訓練 | 取樣與分堆 | 設定batch size，透過batch從訓練目標中取樣，來加快ML模型訓練的速度。(此參數在訓練前設定，為hyper-parameter)。與迭代(iteration),epoch介紹。 |
| 9. ((訓練中) 完成訓練 | (loop) -> 完成 | 重覆過程(評估當前模型好壞 -> 修正模型參數)，直到能通過「驗證資料集(Validation)」的驗證即可結束訓練。 |
| 10. (訓練後) | 訓練結果可能問題 | 「不適當的最小loss?」 |
| 11. (訓練後) | 訓練結果可能問題 | 欠擬合(underfitting)?過度擬合(overfitting)?  |
| 12. (訓練後) | 評估 - 性能指標 | 性能指標(performance metrics)：以混淆矩陣(confusion matrix)分析，包含「Accuracy」、「Precision」、「Recall」三種評估指標。  |
| 13. (訓練後) | 評估 - 新資料適用性 | 泛化(Generalization)：對於新資料、沒看過的資料的模型適用性。 |
| 14. (訓練後) | 評估 - 模型測試 | 使用「獨立測試資料集(Test)」測試. 使用交叉驗證(cross-validation)(又稱bootstrapping)測試. |

### 泛化(generalize)：指ML模型「對未知資料集」的預測能力。

> 泛化(generalize)能力差：等於預測「對未知資料集」的預測能力能力差。  
> 但如果對「對自己的資料」的預測能力很好，有可能是發生了過度擬合(overfitting)的現象。

### ★ 欠擬合(underfitting) 與 過度擬合(overfitting)


| **比較**   | **‌欠擬合(underfitting)**  | **過度擬合(overfitting)** |
| ----------- | --------- | --------------------------------------- |
| (訓練前) | (可能)決定了太簡單的模型 | (可能)決定了太複雜的模型 |
| (訓練中) | (可能)訓練太早結束 | (可能)訓練過頭，也就是太晚結束 |
| (訓練後)對自已的資料 | 訓練後發現模型「對自已的資料」預測能力太差 | 訓練後發現模型「對自已的資料」預測能力非常好(可能好到沒有誤差) |
| (訓練後)對新的資料 | (對自己的資料都不行了還要試新資料嗎XD) | 訓練後發現模型「對新的資料」預測能力非常差 |
| 代表的意義 | 我們的模型「對自已的資料」沒辦法達到理想的預測能力 | 我們的模型「對新的資料」沒辦法達到理想的預測能力，然而對「對自已的資料」預測能力非常好。 |

> [!TIP]
> 「最佳的ML模型訓練結果」應該介於欠擬合(underfitting) 與 過度擬合(overfitting)之間。

#### 用圖簡單解釋 欠擬合(underfitting) 與 過度擬合(overfitting)

使用Matplotlib 來展示欠擬合 (underfitting) 和過度擬合 (overfitting) 的概念，並搭配簡單的例子來說明這兩個現象在機器學習中的區別。

假設我們有一個簡單的非線性數據集，並嘗試用不同複雜度的模型來擬合它：

[**實作的ipynb**](./README.ipynb)

![](./images/pic1.png)




### 擬合模型：
- **欠擬合**：用一次多項式（直線）擬合，無法捕捉數據的非線性趨勢。
- **適當擬合**：用二次多項式（拋物線）擬合，與真實數據的趨勢匹配。
- **過度擬合**：用 10 次多項式擬合，過分捕捉噪聲，導致曲線過於複雜。

