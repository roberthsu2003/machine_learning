# k近鄰分類 k-Nearest Neighbors  Classifier
##  實作:
> [!IMPORTANT]
> 以下實作

**分類實作**

[**真偽和乳癌資料集-細部說明實作**](./README.ipynb)

[**鳶尾花-簡單實作**](./sklearn實作1.ipynb)

[**手寫數字數據集實作-使用GPU**](./sklearn實作2.ipynb)



## k 近鄰分類 (k-Nearest Neighbors, KNN) 的基本概念

**想像一下，我們在玩「找朋友」遊戲：**

* **遊戲目標：** 判斷一個新同學（資料點）應該被分到哪個組別（類別）。
* **遊戲規則：**
    1.  **觀察：** 我們先觀察所有已分組的同學（訓練資料），他們各自屬於不同組別。
    2.  **距離：** 當新同學加入時，我們計算他與所有已分組同學之間的「距離」（相似度）。
    3.  **找鄰居：** 我們找出與新同學最接近的 k 個同學（k 個最近鄰居）。
    4.  **投票：** 觀察這 k 個鄰居，看看哪個組別的同學最多。新同學就加入那個組別。

**舉例說明：**

* 假設我們想判斷一個新同學應該分到「運動組」還是「美術組」。
* 我們觀察到，與新同學考試分數最接近的 5 個同學中，有 3 個是運動組，2 個是美術組。
* 那麼，根據多數決，我們就把新同學分到「運動組」。

**k 近鄰分類的重點：**

* **k 值：** k 值代表我們要找多少個鄰居。k 值的選擇會影響分類結果。
* **距離計算：** 計算距離的方法有很多種，例如歐氏距離。
* **簡單易懂：** k 近鄰分類是一種簡單直觀的分類方法。

**優點：**

* 容易理解和實作。
* 對於多種類別的分類效果不錯。

**缺點：**

* 計算量可能較大。
* 容易受到資料雜訊的影響。

在 k 近鄰 (k-Nearest Neighbors, KNN) 分類中，「k 值」是一個至關重要的參數，它直接影響模型的性能。以下我將詳細解釋 k 值的意義，以及它如何影響模型的性能：

## k 值的意義：

* k 值代表在進行分類時，我們需要考慮距離新資料點最近的「k 個鄰居」。
* 換句話說，當我們要預測一個新資料點的類別時，KNN 演算法會找出距離該點最近的 k 個訓練資料點，並根據這些鄰居的類別來決定新資料點的類別。

**k 值如何影響模型性能：**

* **k 值過小：**
    * 如果 k 值設定得太小（例如 k=1），模型會過度關注局部細節，容易受到雜訊（noise）的影響。
    * 這可能導致過度擬合（overfitting），即模型在訓練資料上表現良好，但在測試資料上表現較差。
    * 模型對於訓練資料中的異常值非常敏感。
* **k 值過大：**
    * 如果 k 值設定得太大，模型可能會過度平滑決策邊界，忽略資料中的局部特徵。
    * 這可能導致欠擬合（underfitting），即模型無法捕捉資料中的複雜模式，在訓練和測試資料上表現都較差。
    * 模型會將很多距離較遠的點也納入判斷，而這些點可能和要判斷的點本身關聯性不大，造成誤判。
* **最佳 k 值的選擇：**
    * 選擇最佳的 k 值是一個需要權衡的問題。
    * 通常，我們會使用交叉驗證（cross-validation）等技術來評估不同 k 值下的模型性能，並選擇性能最佳的 k 值。
    * 通常k會選奇數，避免投票時票數相同，無法判斷的情況發生。
    * 經驗法則：k值通常低於訓練樣本數的平方根。
    * 較好的方法是多嘗試幾個k值，並比較模型預測的準確率，來選擇最佳的k值。

**總結：**

* k 值是 KNN 演算法中的一個重要超參數，它控制著模型在進行分類時考慮的鄰居數量。
* 適當選擇 k 值可以提高模型的性能，避免過度擬合或欠擬合的問題。
* 選擇k值沒有一個固定的最佳值，需要根據資料特性，與多次測試來找到最好的k值。

## k 近鄰分類的應用場景有那一些

k 近鄰 (k-Nearest Neighbors, KNN) 分類演算法由於其簡單且直觀的特性，在許多領域都有廣泛的應用。以下是一些常見的應用場景：

**1. 圖像辨識：**

* KNN 可以用於圖像分類，例如手寫數字辨識或物件辨識。
* 透過提取圖像的特徵（例如像素值或紋理），KNN 可以比較不同圖像之間的相似性，並將其分類到相應的類別。

**2. 推薦系統：**

* 在電子商務或影音平台中，KNN 可以用於推薦商品或內容。
* 透過分析使用者的歷史行為（例如購買紀錄或觀看紀錄），KNN 可以找出與目標使用者相似的其他使用者，並推薦他們喜歡的商品或內容。

**3. 醫學診斷：**

* KNN 可以用於疾病診斷或病情預測。
* 透過分析病患的生理數據或基因資料，KNN 可以找出與目標病患相似的其他病患，並預測其可能的病情或治療效果。

**4. 信用評估：**

* 在金融領域，KNN 可以用於信用評估。
* 透過分析借款人的財務資料或信用紀錄，KNN 可以找出與目標借款人相似的其他借款人，並評估其信用風險。

**5. 文本分類：**

* KNN 可以用於文本分類，例如新聞分類或垃圾郵件過濾。
* 透過提取文本的特徵（例如詞頻或關鍵字），KNN 可以比較不同文本之間的相似性，並將其分類到相應的類別。

**6. 模式識別：**

* KNN 能夠應用在模式辨識上，例如辨識人類行為模式，或是辨識機械的故障模式。

**7. 地理空間分析：**

* KNN 能夠應用在地理空間分析上，例如分析都市內犯罪熱點，或是分析某地區的植物分佈。

**總結來說：**

* KNN 演算法的應用範圍非常廣泛，只要是需要根據相似性進行分類或預測的場景，都可以考慮使用 KNN。
* 由於KNN演算法簡單，因此在許多的初步分析上，都會優先使用KNN來當作基準線。






