# 機率統計

- [待轉換文章1](./參考1.md)


透徹了解「機率分佈」，這是一個至關重要的基礎。因為在機器學習中，我們幾乎所有事情都圍繞著「不確定性」打轉，而機率分佈正是**描述與量化不確定性(不是百分百確定)的語言**。

## 為什麼一個搞 AI/ML 的人需要懂機率分佈？

### 問題:

目的:機率分佈不是一個純理論的數學工具，而是解決真實 ML 問題的核心。

假設我們要做一個貓狗分類器，當模型輸出『90% 是貓』時，這 90% 是什麼意思？它背後是什麼數學模型？」(伯努利分佈(Bernoulli distribution)/分類分佈(Classification distribution))



圖表：貓狗分類器對單一圖片的預測分佈圖(Bernoulli distribution)
![](./images/pic3.png)

假設我們要做一個動物分類器，模型要判斷一張圖片是「貓」、「狗」還是「兔子」三種之一。當模型輸出結果如下：

- 70% 是貓
- 20% 是狗
- 10% 是兔子

這三個數字分別代表什麼意思？它背後是什麼數學模型？

分類分佈圖表 (Categorical Distribution Chart)

![](./images/pic4.png)

補充：
- 如果只有兩個類別（例如「貓」和「狗」），這就是「伯努利分佈（Bernoulli distribution）」。
- 如果有三個以上的類別，就是「多項分佈（Multinomial distribution）」的單次試驗情況，也稱「分類分佈（Categorical distribution）」。

---

「我們要預測明天台北的氣溫，模型預測是 25°C。但我們有多大的把握？氣溫落在 23°C 到 27°C 之間的機率有多高？」(常態分佈)

常態分佈圖表(Normal distribution chart)
![](./images/pic5.png)

---


## 隨機變數（Random Variable)  

- 說明1:隨機變數是對隨機事件結果的數值描述。例如，擲骰子的結果可以用一個數值來表示（如1到6）。
	- 1點 -> 1
	- 2點 -> 2
	- 3點 -> 3
	- 4點 -> 4
	- 5點 -> 5
	- 6點 -> 6

- 說明2:是一個將隨機實驗結果對應到數值的函數

```python
import numpy as np

# 模擬擲骰子 10 次，每次結果為 1~6 的整數
dice_rolls = np.random.randint(1, 7, size=10)
print("擲骰子的結果（隨機變數 X）:", dice_rolls)
```

## 離散隨機變數(Discrete Random Variable) 
離散隨機變數就是「可以一個一個獨立出來」的隨機變數。也就是說，它的所有可能結果不是有限個，就是雖然很多但還是可以一個一個列出來。舉例來說，擲骰子的點數只有 1、2、3、4、5、6 這六種，這就是離散隨機變數。

**主要特徵**
- 有限或可數無窮個: 例如擲骰子的結果（1,2,3,4,5,6）、投硬幣的結果（正面、反面）、或某段時間內電話接聽次數（0,1,2,…）
- 每個值有對應機率: 可以明確寫出每個可能值的機率，稱為「機率分佈」
- 機率總和為1

**常見例子**

| 例子 | 可能的取值 |
|:--|:--|
| 擲骰子 | 1, 2, 3, 4, 5, 6 |
| 投硬幣（只看正反面） | 0（反面）、1（正面） |
| 投籃命中次數 | 0, 1, 2, …, n |

**總結**  
離散隨機變數就是「可以一一列出所有可能值」的隨機變數，每個值都有明確的機率

**2項式分佈的python範例**
好的，這是一個口語化、像聊天一樣解釋「二項分佈」的方式：

---

### 2項式分佈說明

想像一下，你在做一個很簡單的實驗，而且要重複做好幾次。這個實驗有個特點，就是每次的結果只有兩種可能，不是「成功」就是「失敗」。

好，要滿足「二項分佈」，你需要檢查四件事情：

1.  **固定的次數**：你要一開始就決定好，這個實驗總共要做幾次。比方說，你決定要「丟 10 次硬幣」，這個 10 就是固定的，不能丟到一半想多丟或少丟。

2.  **只有兩種結果**：每次實驗的結果，只能是你要的那個（我們叫它「成功」），或不是你要的那個（我們叫它「失敗」）。比如丟硬幣，你可能把「正面」當作成功，「反面」就是失敗。或者像品管員檢查產品，結果只有「良品」（成功）或「瑕疵品」（失敗）。

3.  **機率都一樣**：每一次實驗，成功的機率都是固定的，不會變來變去。像丟一枚公正的硬幣，不管你丟第幾次，出現正面的機率永遠都是 50%。不會因為你前面丟了很多次正面，下一次的機率就變了。

4.  **每次都獨立**：這一次的實驗結果，不會影響到下一次的結果。你這次丟硬幣是正面，跟你下次丟出正面還是反面，一點關係都沒有。它們是獨立事件。

**所以，二項分佈在幹嘛呢？**

它就是在幫你算：「**在固定做 N 次實驗後，剛剛好成功 K 次的機率是多少？**」

**舉個例子：**

假設有個籃球員，他罰球的命中率是 80% (也就是 0.8)。
現在他要罰球 5 次（**固定次數 N=5**）。

我們想問：「**他這 5 次球裡，剛剛好投進 3 球（成功 K=3 次）的機率是多少？**」

這就是一個標準的二項分佈問題！因為：
1.  他總共罰 5 次（固定次數）。
2.  每次不是「投進」（成功）就是「沒投進」（失敗）。
3.  他每次投進的機率都是 80%（機率固定）。
4.  這一球有沒有進，不會影響下一球的命中率（互相獨立）。

二項分佈就是用來計算這種問題的數學工具。你可以用它來算「5 球全進」、「剛好進 1 球」或「至少進 4 球」等等的機率。

```python
import numpy as np

# 模擬投擲硬幣 10 次，0 表示反面，1 表示正面
# 什麼是二項式亂數？
# 在 numpy 中，可以用 np.random.binomial 來產生這種亂數。
coin_flips = np.random.binomial(n=1, p=0.5, size=10)
# n 代表「每一次試驗中重複進行的次數」。
# 在這裡 n=1，表示每次只拋一次硬幣（即每次試驗只有一次成功或失敗的機會）。
# 如果 n=3，則代表每次試驗會連續拋3次硬幣，並記錄其中正面的次數。
# p=0.5：每次成功（例如拋到正面）的機率是 0.5。
# size=10：總共重複這個試驗 10 次，得到 10 個結果。
print("投擲硬幣的結果（離散隨機變數 Y）:", coin_flips)
# 這段程式碼會產生一個長度為 10 的陣列，表示投擲硬幣 10 次的結果。
# 陣列中的每個元素是 0 或 1，分別表示反面或正面。
# 例如，如果結果是 [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]，表示投擲硬幣 10 次，其中有 5 次是正面，5 次是反面。
#---
### 這個範例的離散隨機變數是什麼值？

# 在這個範例中，離散隨機變數 (Y)代表「每一次投擲硬幣的結果」，其可能的取值為：
# - 0（表示反面）
# - 1（表示正面）

# 也就是說，對於每一次投擲，(Y)只能是 0 或 1 其中之一。這就是一個典型的離散隨機變數，因為它的所有可能值可以一一列舉出來。

# **總結：**
# - 離散隨機變數 (Y)的可能值：0、1
# - 每個值分別代表一次投擲硬幣的結果（反面或正面）

# ---
```


## 連續隨機變數

連續隨機變數（Continuous Random Variable）是指「取值為某一區間內的實數，且這些數值是不可數無限多個」的隨機變數。也就是說，連續隨機變數的可能值無法一一列舉，而是「遍布」在某個或整個實數區間內

**主要特徵**  
- **不可數無限多個取值**: 不可數無限多個取值：例如身高、體重、溫度、時間、薪資等，這些數值通常介於某個區間內，且無法一一列出

> 身高理論上可以量測到極小單位，例如 170 公分、170.1 公分、170.01 公分、170.001 公分…可以無限細分下去。

- **單一值的機率為零**:
對於連續隨機變數，任一點的機率為0，機率只存在於某個區間內

> 連續型隨機變數的機率是以「機率密度函數（PDF）」曲線下某區間的面積來表示。單一值（如身高=170.0公分）對應的「區間」寬度為0，因此面積（即機率）為0

- **機率以區間面積計算**:
- 機率以區間面積計算：連續隨機變數的機率是以「機率密度函數（PDF）」曲線下某區間的面積來表示

> 因為連續型隨機變數的取值是不可數無限多個，且機率是以區間面積來定義，所以單一值的機率為0

**常見例子**

| 例子 | 可能取值區間 |
|:--|:--|
| 身高 | 例如 100~220 cm |
| 體重 | 例如 30~150 kg |
| 溫度 | 例如 0~40 ℃ |
| 時間 | 例如 0~∞ 秒 |

```python
import numpy as np

# 連續隨機變數的範例說明與模擬

# 連續隨機變數的特點：
# - 可以取某個區間內的任意實數值，無法一一列舉
# - 例如「身高」這個變數，理論上可以是 170.0、170.01、170.001...，甚至 170.0000001 公分
# - 在統計上，這類變數通常用常態分佈（Normal Distribution）來建模

# 以下用 numpy 模擬 10 筆身高資料（單位：公分），假設全體平均身高為 170 公分，標準差為 10 公分
import numpy as np

# 這裡的 loc=170 表示常態分佈的「平均數」（μ），scale=10 表示「標準差」（σ），size=10 表示要產生 10 筆資料
# 標準差（σ）代表資料分布的離散程度，數值越大，資料分布越分散。以本例來說，平均數是170，標準差是10，表示大多數資料會落在170左右，但也有可能出現比170大或小很多的值。
# 例如，產生的資料中可能會有190（比平均數大2個標準差），這是因為常態分佈的特性，數值有機會落在平均數的兩倍標準差之外。
# 換句話說，標準差決定了資料「擴散」的範圍，並不是所有值都會很接近平均數。
heights = np.random.normal(loc=170, scale=10, size=10)
print("模擬身高資料（連續隨機變數 Z）：", heights)

# 說明：
# heights 這個陣列中的每一個值，都是從一個「連續」的常態分佈隨機抽取出來的
# 這代表每個人的身高理論上都可以是 170.0、170.01、169.999...等無窮多個可能值
# 這就是連續隨機變數的特性：在某個區間內有無限多個可能值，且每個精確值的機率為 0
```

## 離散隨機變數的概率分佈
**概率質量分佈(PMF)**

- **特性**:
	- 非負性
	- 總和為1

- **例子**:

假設擲一顆公平骰子，X代表出現的點數，則 PMF 如下：

| x | P(X=x) |
|:--|:--|
| 1 | 1/6 |
| 2 | 1/6 |
| 3 | 1/6 |
| 4 | 1/6 |
| 5 | 1/6 |
| 6 | 1/6 |

[**範例說明PMF**](./PMF概率質量分佈.ipynb)




## 連續隨機變數的概率分佈
**概率密度分佈(PDF)**  
概率密度函數（Probability Density Function, PDF） 是用來描述連續型隨機變數在某個取值點附近「出現可能性」的函數。PDF 本身不是機率，而是用來計算某個區間內機率的「密度」

**[範例說明PDF](./PDF概率密度分佈.ipynb)** 

----

## 2. 常見機率分佈

### 2.1 常態分佈（Normal Distribution）- 連續分佈

**numpy建立理論常態分佈**

```python
import numpy as np

# 生成 5 個符合均值 0、標準差 1 的正態分佈數值
normal_data = np.random.normal(loc=0, scale=1, size=5)
print(normal_data)
```

**高斯分佈(Gaussian distribution),常態分佈（normal distribution)**

![](./images/pic2.png)


➜ 高斯分佈（Gaussian distribution），也稱為常態分佈（normal distribution），是一種連續概率分佈，常用於描述自然界中許多現象的數據分佈。它的特徵是數據分佈呈現鐘形曲線（bell-shaped curve），具有以下關鍵特性：

1. **對稱性**：曲線以平均值（mean, μ）為中心，左右對稱。
2. **集中性**：大多數數據點分佈在平均值附近，隨著數據值偏離平均值，出現的概率逐漸減少。
3. **參數**：由兩個參數決定：
	- 平均值（μ）：表示數據的中心位置。
	- 標準差（σ）: ：表示數據的分散程度，標準差越大，曲線越扁平。?

> [!IMPORTANT]
> 高斯分佈之所以重要，是因為許多自然現象（如身高、考試成績、測量誤差等）的數據分佈近似符合高斯分佈，這使得它在統計學和機器學習中廣泛應用。

**➜機器學習常說「特徵符合高斯分佈」**  

在機器學習中，特別是 GaussianNB（高斯單純貝氏模型），假設每個特徵的數據分佈符合高斯分佈，意味著：

- 該特徵的數值是連續的（例如身高、溫度）。
- 這些數值的分佈形狀近似鐘形曲線，大多數值集中在平均值附近，極端值（很小或很大）的出現概率較低。
- GaussianNB 使用高斯分佈的概率密度函數來估計每個特徵在不同類別下的概率，從而進行分類。

如果特徵的數據分佈偏離高斯分佈（例如呈現偏態或多峰分佈），GaussianNB 的表現可能會受到影響，因為它的假設不再完全成立。

**➜實際的例子**  

假設您正在研究學生的身高數據，來預測他們是否適合參加籃球隊：

- **特徵**：身高（連續數據，單位：厘米）。  
- **數據分佈**：假設身高數據符合高斯分佈，平均值 μ = 170 cm，標準差 σ = 10 cm。  
- **分佈特性**：  
	- 大多數學生身高集中在 160 cm 到 180 cm 之間（約 68% 的數據在 μ ± σ 範圍內）。  
	- 極端值（例如 140 cm 或 200 cm）的學生很少出現。  
	- 鐘形曲線：如果畫出身高分佈的直方圖，它會呈現一個對稱的鐘形曲線，中心在 170 cm。  

- **視學化理解**

1. 鐘形曲線：如果畫出身高分佈的直方圖，它會呈現一個對稱的鐘形曲線，中心在 170 cm。
2. 說明曲線下的面積表示概率，例如
	- 約 68% 的數據落在 μ ± σ 範圍內。
	- 約 95% 的數據落在 μ ± 2σ 範圍內。
3. 實際例子（如身高、考試成績）對照，強調「大多數數據集中在中間，極端值少見」。

**➜實作範例**

[**正態(常態)分佈實作ipynb檔**](./正態分佈.ipynb)

[**使用Q-Q圖(Quantile-Quantile Plot)是否為常態分佈-ipynb檔**](./正態分佈1.ipynb)



### 2.2. 均勻分佈（Uniform Distribution）- 連續分佈

均勻分佈是一種概率分佈，其中隨機變數在指定區間內的每個值具有相等的出現概率。

**講解情境：公車等待時間**  
**場景**：假設一輛公車每隔10分鐘到站一次，且到站時間在一天內是隨機的。你在任意時刻到達公交站，等待時間𝑋,（單位：分鐘）是一個隨機變數。

[**均勻分佈實作ipynb檔**](./均勻分佈.ipynb)

```other
uniform_data = np.random.uniform(low=0, high=10, size=5)
print(uniform_data)
```

**範例說明**

好的，這個 Python 範例是**用來模擬您所描述的「公車等待時間」情境**。

讓我們來逐一拆解這段程式碼的意思：

```python
import numpy as np # 這行通常會放在最前面，是為了載入 NumPy 函式庫

uniform_data = np.random.uniform(low=0, high=10, size=5)
print(uniform_data)
```

這段程式碼的核心是 `np.random.uniform()` 這個函式，它會產生符合均勻分佈的隨機數字。

### 程式碼逐項解釋：

  * **`np.random.uniform(...)`**:

      * 這是 NumPy 函式庫中用來生成「均勻分佈」隨機數的指令。
      * 你可以把它想像成一個模擬器，它知道如何在一個範圍內公平地（uniformly）抽出數字。

  * **`low=0`**:

      * 這設定了隨機數的**最小值**（下界）。
      * 在您的「公車等待時間」情境中，這代表最幸運的情況：你一到站，公車剛好也到了，所以等待時間是 **0 分鐘**。

  * **`high=10`**:

      * 這設定了隨機數的**最大值**（上界）。
      * 在您的情境中，這代表最不走運的情況：你剛好錯過前一班車，必須等滿整整 **10 分鐘**，下一班車才會來。

  * **`size=5`**:

      * 這代表你想要**產生幾個**這樣的隨機數。
      * 在您的情境中，這可以解釋為「**模擬 5 個人**在不同時間點到達公車站時，他們各自的等待時間」。

### 總結程式碼的意思

`uniform_data = np.random.uniform(low=0, high=10, size=5)` 這整行程式碼的白話文就是：

> 「**請模擬一個在 0 到 10 分鐘之間均勻分佈的公車等待時間，並隨機產生 5 個這樣的等待時間紀錄。**」

當你執行 `print(uniform_data)`，你會看到一個類似下面這樣的陣列（每次執行結果都會不同）：

```
[8.56836619 2.30251741 7.31688632 0.83582136 5.37322921]
```

這個輸出的意思是：

  * 第一個人等了約 8.6 分鐘。
  * 第二個人等了約 2.3 分鐘。
  * 第三個人等了約 7.3 分鐘。
  * ...依此類推，總共記錄了 5 個人的隨機等待時間。

你會發現，所有產生的數字都會落在 `0` 和 `10` 之間，並且每個數字（例如 1.5 分鐘、3 分鐘、9.9 分鐘）被抽中的機會都是均等的，這完美地對應了您對「均勻分佈」的定義。

### 2.3 指數分佈(Exponential) - 連續分佈

### 2.4  二項分佈（Binomial Distribution） - 離散分佈

[**2項分佈實作ipynb檔**](./二項分佈.ipynb)

```other
# 進行 10 次獨立拋硬幣試驗，成功機率為 0.5
binomial_data = np.random.binomial(n=10, p=0.5, size=5)
print(binomial_data)
```

### 2.5 泊松分佈(Poisson) - 離散分佈

### 2.6 伯努利分佈(Bernoulli) - 離散分佈

----

## 3. [Quantile-Quantile Plot](./Q-Q圖)（簡稱 Q-Q 圖）

是一種圖形工具，用於檢查數據的分佈是否符合某個特定的理論分佈，或者比較兩個數據集的分佈是否相似。

![](./images/pic1.png)

---



## 4. 基本統計計算

**使用 numpy 計算常見統計量**：

```other
data = [12, 15, 20, 25, 30]

# 平均數
print("平均數:", np.mean(data))

# 中位數
print("中位數:", np.median(data))

# 標準差
print("標準差:", np.std(data))

# 變異數
print("變異數:", np.var(data))
```

----

**4. 機率密度函數與累積分佈函數**

使用 scipy.stats 計算機率分佈相關函數。

**(1) 計算某數值在標準正態分佈下的機率**

```other
from scipy.stats import norm

x = 1.0  # 目標數值
pdf_value = norm.pdf(x, loc=0, scale=1)  # 機率密度函數
cdf_value = norm.cdf(x, loc=0, scale=1)  # 累積分佈函數

print("PDF:", pdf_value)
print("CDF:", cdf_value)
```


**(2) 計算某數值在二項分佈下的機率**

```other
from scipy.stats import binom

n, p, k = 10, 0.5, 3  # 10 次試驗, 成功機率 0.5, 觀察 3 次成功
prob = binom.pmf(k, n, p)
print(f"成功 {k} 次的機率: {prob}")
```


