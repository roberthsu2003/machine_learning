{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "195f0743",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthsu2003/machine_learning/blob/main/%E6%A8%B9%E7%8B%80%E6%A8%A1%E5%9E%8B/demo2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eb6a625",
      "metadata": {
        "id": "0eb6a625"
      },
      "source": [
        "- 我們使用完全開發樹的預設（生長樹直到所有葉子都pure）來建立模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03ba8ec4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ba8ec4",
        "outputId": "01a5a62f-e745-4508-8864-c6e9cd0fd087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "訓練集的準確度: 1.000\n",
            "測試集的準確度: 0.937\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "cancer.data, cancer.target, stratify=cancer.target, random_state=42) #參考下面說明1\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=0) #參考下面說明2\n",
        "tree.fit(X_train, y_train)\n",
        "print(\"訓練集的準確度: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"測試集的準確度: {:.3f}\".format(tree.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a021c765",
      "metadata": {
        "id": "a021c765"
      },
      "source": [
        "### 結果說明\n",
        "不出所料，在**訓練集上的準確率是100%**  \n",
        "- 因為leaf是pure的，樹的成長深度足以讓它完全記住訓練資料上的所有標籤。\n",
        "\n",
        "- 測試集的準確率比我們之前研究過的線性模型略差，後者的準確率約為 95%。\n",
        "\n",
        "- 如果我們不限制決策樹的深度，那麼樹可以變得任意深和複雜。因此，`未修剪的樹容易過度擬合，並且不能很好地推廣到新數據`。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6a4b6f",
      "metadata": {},
      "source": [
        "### 說明1\n",
        "scikit-learn 的 train_test_split 函數來將乳癌資料集（cancer.data 和 cancer.target）分割成訓練集（X_train, y_train）和測試集（X_test, y_test）。\n",
        "\n",
        "stratify 和 random_state 這兩個參數：\n",
        "\n",
        "- **stratify=cancer.target:**\n",
        "\n",
        "**作用**: 這個參數的目的是在分割資料時，確保訓練集和測試集中各個類別（在這個例子中是良性腫瘤和惡性腫瘤）的比例與原始資料集（cancer.target）中的比例大致相同。這稱為「分層抽樣」。  \n",
        "**重要性**: 在分類問題中，特別是當某些類別的樣本數量遠少於其他類別時（類別不平衡），分層抽樣非常重要。如果不使用 stratify，隨機分割可能會導致訓練集或測試集中某個類別的樣本過多或過少，這會影響模型的訓練效果和評估的準確性。例如，如果測試集中幾乎沒有惡性腫瘤的樣本，那麼模型在測試集上的表現可能無法真實反映其對惡性腫瘤的預測能力。  \n",
        "**如何運作**: train_test_split 會查看 cancer.target 中的標籤分佈，並根據這個分佈比例來抽取樣本到訓練集和測試集。\n",
        "\n",
        "- **random_state=42:**\n",
        "\n",
        "- **作用**: train_test_split 在分割資料前會先隨機打亂資料的順序。random_state 參數用於控制這個隨機過程。當你設定一個固定的整數（例如 42）給 random_state 時，它會初始化隨機數生成器。  \n",
        "- **重要性**: 設定 random_state 可以確保每次執行這段程式碼時，資料分割的結果都是完全一樣的。這對於實驗的可重複性非常重要。如果你或其他人在不同的時間或不同的機器上運行相同的程式碼，只要 random_state 設成相同的值，就能得到相同的訓練集和測試集，從而可以比較不同模型或參數調整的效果。  \n",
        "- **如何運作**: 這個數字（42）本身沒有特殊意義，你可以選擇任何整數。重要的是，只要使用相同的數字，隨機分割的結果就會固定下來。如果將 random_state 設為 None 或不設定，那麼每次執行程式碼時，資料分割的結果都會不同。  \n",
        "\n",
        "**總結來說**：\n",
        "\n",
        "stratify=cancer.target 確保分割後的訓練集和測試集在目標變數（腫瘤類別）上的比例與原始資料集一致。\n",
        "random_state=42 確保每次執行程式碼時，資料分割的方式都相同，使得結果可以重現。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf730d69",
      "metadata": {},
      "source": [
        "### 說明2\n",
        "\n",
        "**random_state=0**：\n",
        "\n",
        "random_state=0:\n",
        "**作用**: 在決策樹的建構過程中，有時會遇到隨機性。例如，當演算法在選擇最佳分割特徵時，如果有多個特徵都能帶來相同的資訊增益（或 Gini 不純度降低量），演算法可能需要隨機選擇其中一個。同樣地，如果設定 splitter='random'（雖然這裡用的是預設的 'best'），也會引入隨機性。random_state 參數就是用來控制這種內部隨機性的。  \n",
        "**重要性**: 設定一個固定的整數（例如 0）給 random_state，可以確保每次執行這段程式碼時，即使存在需要隨機決策的步驟，決策樹的結構也會是完全一樣的（前提是訓練資料相同）。這對於結果的可重現性非常重要。如果你想比較不同參數設定對決策樹模型的影響，固定 random_state 可以排除隨機性帶來的干擾。  \n",
        "**如何運作**:這個數字（0）本身沒有特殊意義，你可以選擇任何整數。重要的是，只要使用相同的數字，演算法內部的隨機數生成器就會被初始化為相同的狀態，從而產生相同的隨機決策順序，最終建構出相同的決策樹。如果將 random_state 設為 `None 或不設定`，那麼每次執行時，如果遇到需要隨機選擇的情況，結果可能會不同，導致每次訓練出的樹結構略有差異。  \n",
        "**總結來說**，在 DecisionTreeClassifier(random_state=0) 中，random_state=0 確保了決策樹建構過程中的隨機性是可控的，使得每次運行程式碼都能得到完全相同的模型結構，方便實驗比較和結果重現。這與之前在 train_test_split 中使用 random_state=42 的目的一致，都是為了確保實驗過程的可重複性。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
