{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthsu2003/machine_learning/blob/main/%E8%B2%9D%E6%B0%8F%E5%88%86%E9%A1%9E/sklearn%E5%AF%A6%E4%BD%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_ac0Cis3TGe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RauI1zBg3TGf"
      },
      "outputs": [],
      "source": [
        "#下載字型\n",
        "import wget\n",
        "wget.download(\"https://github.com/roberthsu2003/machine_learning/raw/refs/heads/main/source_data/ChineseFont.ttf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnJFXSV-3TGf"
      },
      "source": [
        "### 如何使用 scikit-learn 的 `GaussianNB` 模型來進行分類。\n",
        "- 我們將使用一個簡單的數據集，其中包含兩個特徵（例如，花瓣長度和花瓣寬度），並預測鳶尾花的種類（0、1 或 2）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDAx_nEiNnv2"
      },
      "source": [
        "### Iris 資料集中每一筆資料長這樣：\n",
        "特徵：\n",
        "- 花萼長度\n",
        "- 花萼寬度\n",
        "- 花瓣長度\n",
        "- 花瓣寬度\n",
        "\n",
        "目標類別：\n",
        "- 山鳶尾 / 變色鳶尾 / 維吉尼亞鳶尾\n",
        "\n",
        "### 條件獨立假設意思是：\n",
        "在已知花的品種（例如：Setosa）的情況下:\n",
        "\n",
        "→ 花萼長度和花瓣長度的機率是獨立的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9YETNW53TGg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib as mlp\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "fontManager.addfont('ChineseFont.ttf')\n",
        "mlp.rc('font', family='ChineseFont')\n",
        "\n",
        "# 1. 載入數據集\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]  # 花萼長度和花萼寬度\n",
        "y = iris.target\n",
        "\n",
        "# 2. 分割訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. 建立高斯樸素貝葉斯模型\n",
        "model = GaussianNB()\n",
        "\n",
        "# 4. 訓練模型\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. 進行預測\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. 評估模型\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"模型準確度：{accuracy:.2f}\")\n",
        "\n",
        "# 7. 可視化決策邊界\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
        "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor='k')\n",
        "plt.xlabel(iris.feature_names[0])\n",
        "plt.ylabel(iris.feature_names[1])\n",
        "plt.title('高斯樸素貝葉斯分類邊界')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMxj2ChDNnv3"
      },
      "source": [
        "### 以下範例有包含\n",
        "- Q-Q圖\n",
        "- 準確率\n",
        "- 混淆矩陣(熱力圖)\n",
        "- 分類報告"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlbRVpWHNnv4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib as mlp\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "# 設置中文字體（確保圖表顯示中文）\n",
        "fontManager.addfont('ChineseFont.ttf')\n",
        "mlp.rc('font', family='ChineseFont')\n",
        "\n",
        "# 1. 載入 Iris 數據集\n",
        "iris = load_iris()\n",
        "X = iris.data  # 特徵：花萼長度、花萼寬度、花瓣長度、花瓣寬度\n",
        "y = iris.target  # 類別：0, 1, 2（三種鳶尾花品種）\n",
        "feature_names = ['花萼長度', '花萼寬度', '花瓣長度', '花瓣寬度']  # 特徵名稱改為中文\n",
        "class_names = ['山鳶尾', '變色鳶尾', '維吉尼亞鳶尾']  # 類別名稱改為中文\n",
        "\n",
        "# 2. 檢查特徵是否符合高斯分佈，使用 Q-Q 圖\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(X.shape[1]):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    stats.probplot(X[:, i], dist=\"norm\", plot=plt)\n",
        "    plt.title(f'{feature_names[i]} 的 Q-Q 圖')\n",
        "    plt.xlabel('理論分量')\n",
        "    plt.ylabel('樣本分量')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. 將數據分為訓練集和測試集（80% 訓練，20% 測試）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. 訓練 GaussianNB 模型\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. 預測測試集\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. 評估模型\n",
        "# 計算準確率\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"模型準確率: {accuracy:.2f}\")\n",
        "\n",
        "# 繪製混淆矩陣\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('混淆矩陣')\n",
        "plt.xlabel('預測類別')\n",
        "plt.ylabel('實際類別')\n",
        "plt.show()\n",
        "\n",
        "# 輸出分類報告（精確率、召回率、F1 分數）\n",
        "print(\"\\n分類報告:\")\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL72LDnaNnv4"
      },
      "source": [
        "為了幫助您向學生展示 **GaussianNB** 在真實體數據上的應用，我將提供一個完整的範例，包含使用 Python 的 `scikit-learn` 庫來訓練模型、評估模型表現，並檢查特徵是否符合高斯分佈假設。這個範例將使用一個公開的真實數據集（**Iris 數據集**），因為它簡單、易懂，且特徵是連續數據，非常適合 GaussianNB 和教學用途。範例將包括程式碼、Q-Q 圖檢查、模型訓練與評估，並以清晰、正式的語氣撰寫，確保學生能夠快速理解。\n",
        "\n",
        "---\n",
        "\n",
        "### 範例目標\n",
        "- **數據集**：Iris 數據集，包含 150 個樣本，每個樣本有 4 個連續特徵（花萼長度、花萼寬度、花瓣長度、花瓣寬度）和 3 個類別（三種鳶尾花品種）。\n",
        "- **任務**：使用 GaussianNB 進行分類，預測花的品種。\n",
        "- **步驟**：\n",
        "  1. 檢查特徵是否近似高斯分佈（使用 Q-Q 圖）。\n",
        "  2. 訓練 GaussianNB 模型。\n",
        "  3. 評估模型表現（使用準確率、混淆矩陣和分類報告）。\n",
        "- **教學目標**：讓學生理解 GaussianNB 的應用、特徵分佈的重要性，以及如何評估分類模型。\n",
        "\n",
        "---\n",
        "\n",
        "### 程式碼範例\n",
        "以下是完整的 Python 程式碼，包含數據載入、Q-Q 圖檢查、模型訓練與評估。程式碼使用 `scikit-learn`、`numpy`、`matplotlib` 和 `scipy`，並附有詳細註釋以便學生理解。\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. 載入 Iris 數據集\n",
        "iris = load_iris()\n",
        "X = iris.data  # 特徵：花萼長度、花萼寬度、花瓣長度、花瓣寬度\n",
        "y = iris.target  # 類別：0, 1, 2（三種鳶尾花品種）\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# 2. 檢查特徵是否符合高斯分佈，使用 Q-Q 圖\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(X.shape[1]):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    stats.probplot(X[:, i], dist=\"norm\", plot=plt)\n",
        "    plt.title(f'Q-Q Plot for {feature_names[i]}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. 將數據分為訓練集和測試集（80% 訓練，20% 測試）\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. 訓練 GaussianNB 模型\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. 預測測試集\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. 評估模型\n",
        "# 計算準確率\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"模型準確率: {accuracy:.2f}\")\n",
        "\n",
        "# 繪製混淆矩陣\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "# 輸出分類報告（精確率、召回率、F1 分數）\n",
        "print(\"\\n分類報告:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 程式碼解釋\n",
        "1. **載入數據**：\n",
        "   - 使用 `load_iris()` 載入 Iris 數據集，包含 4 個連續特徵和 3 個類別。\n",
        "   - 特徵是連續值（例如花萼長度 5.1 cm），適合 GaussianNB。\n",
        "\n",
        "2. **檢查高斯分佈**：\n",
        "   - 使用 Q-Q 圖（`stats.probplot`）檢查每個特徵是否近似高斯分佈。\n",
        "   - 每個特徵生成一個 Q-Q 圖，如果點接近對角線，則特徵分佈接近高斯分佈。\n",
        "   - 這一步讓學生理解 GaussianNB 的假設（特徵符合高斯分佈）。\n",
        "\n",
        "3. **數據分割**：\n",
        "   - 將數據分為訓練集（80%）和測試集（20%），確保模型在未見數據上評估泛化能力。\n",
        "\n",
        "4. **訓練模型**：\n",
        "   - 使用 `GaussianNB` 訓練模型，假設特徵符合高斯分佈，計算每個類別的均值和標準差。\n",
        "\n",
        "5. **模型評估**：\n",
        "   - **準確率**：計算預測正確的比例。\n",
        "   - **混淆矩陣**：視覺化顯示每個類別的預測結果，幫助學生理解哪些類別容易混淆。\n",
        "   - **分類報告**：提供精確率（precision）、召回率（recall）和 F1 分數，全面評估模型表現。\n",
        "\n",
        "---\n",
        "\n",
        "### 預期輸出\n",
        "運行程式碼後，學生將看到：\n",
        "1. **Q-Q 圖**：\n",
        "   - 4 個特徵的 Q-Q 圖，顯示每個特徵的分佈是否接近高斯分佈。\n",
        "   - 例如，花瓣長度可能接近對角線（近似高斯分佈），而花萼寬度可能略有偏離（輕微偏態）。\n",
        "\n",
        "2. **準確率**：\n",
        "   - 輸出類似「模型準確率: 0.97」，表示模型在測試集上的表現（Iris 數據集通常有高準確率）。\n",
        "\n",
        "3. **混淆矩陣**：\n",
        "   - 一個 3x3 的熱圖，顯示每個類別的預測結果。例如：\n",
        "     ```\n",
        "     [[10  0  0]\n",
        "      [ 0  9  1]\n",
        "      [ 0  0 10]]\n",
        "     ```\n",
        "     表示大多數預測正確，少數錯誤（如 1 個 versicolor 被誤分類）。\n",
        "\n",
        "4. **分類報告**：\n",
        "   - 顯示每個類別的精確率、召回率和 F1 分數，例如：\n",
        "     ```\n",
        "     分類報告:\n",
        "                  precision    recall  f1-score   support\n",
        "     setosa          1.00      1.00      1.00        10\n",
        "     versicolor      0.90      0.90      0.90        10\n",
        "     virginica       0.91      0.91      0.91        10\n",
        "     ```\n",
        "\n",
        "---\n",
        "\n",
        "### 教學建議\n",
        "1. **引導學生理解 Q-Q 圖**：\n",
        "   - 展示 Q-Q 圖後，問學生：「如果點偏離對角線，會對 GaussianNB 的表現有什麼影響？」（答：可能降低模型準確性，因為假設不完全成立）。\n",
        "   - 解釋即使特徵不完全符合高斯分佈，GaussianNB 仍可能表現良好（Iris 數據集是一個例子）。\n",
        "\n",
        "2. **強調泛化能力**：\n",
        "   - 說明測試集的準確率反映模型的泛化能力，問學生：「為什麼我們不用訓練集來評估模型？」（答：因為模型可能過擬合訓練數據）。\n",
        "\n",
        "3. **視覺化效果**：\n",
        "   - 混淆矩陣的熱圖能直觀展示模型的錯誤，幫助學生理解哪些類別容易混淆（例如 versicolor 和 virginica）。\n",
        "   - 鼓勵學生檢查混淆矩陣中的錯誤，思考是否與特徵分佈有關。\n",
        "\n",
        "4. **互動練習**：\n",
        "   - 讓學生修改程式碼，例如：\n",
        "     - 只使用 2 個特徵（例如花瓣長度和寬度）重新訓練模型，觀察準確率變化。\n",
        "     - 改變 `test_size`（例如 0.3），看看測試集大小如何影響結果。\n",
        "   - 問學生：「如果我們用一個非高斯分佈的數據集，GaussianNB 會表現如何？」引導他們思考模型假設的局限性。\n",
        "\n",
        "5. **連繫真實應用**：\n",
        "   - 說明 Iris 數據集雖然簡單，但類似的連續特徵（例如醫療數據中的血壓、體重）在真實世界中很常見，GaussianNB 適用於這些場景。\n",
        "\n",
        "---\n",
        "\n",
        "### 為什麼選擇 Iris 數據集？\n",
        "- **簡單易懂**：4 個特徵，3 個類別，數據量小（150 個樣本），適合初學者。\n",
        "- **連續特徵**：特徵是連續值，符合 GaussianNB 的假設。\n",
        "- **公開可用**：內建於 `scikit-learn`，無需額外下載。\n",
        "- **高準確率**：GaussianNB 在 Iris 數據集上通常表現良好（準確率約 95%），讓學生對模型有信心，同時可以討論少數錯誤的原因。\n",
        "\n",
        "---\n",
        "\n",
        "### 總結\n",
        "- 這個範例使用 Iris 數據集展示了 GaussianNB 的完整應用流程：檢查特徵分佈（Q-Q 圖）、訓練模型、評估表現（準確率、混淆矩陣、分類報告）。\n",
        "- 程式碼簡單且有詳細註釋，適合學生學習，並可作為課堂演示或作業基礎。\n",
        "- 通過視覺化（Q-Q 圖、混淆矩陣）和問題引導，學生能深入理解 GaussianNB 的假設和應用。\n",
        "\n",
        "如果您需要調整範例（例如使用其他數據集、增加交叉驗證、或更詳細的數學解釋），或希望提供給學生的講義版本，請隨時告知！"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}