# 貝氏分類 Naive Bayes Classifier

貝氏分類（Naive Bayes Classifier）是機器學習中非常經典且直觀的分類演算法，適合用來做為學生入門機率與機器學習思維的橋樑。以下是介紹方式與學習重點：

## 重點:
- 解釋貝氏定理和樸素貝葉斯分類的基本概念，包括條件機率和特徵獨立性假設。
- 解釋高斯樸素貝葉斯如何處理連續型特徵。
- 解樸素貝葉斯分類的優缺點，例如簡單高效、對數據量要求不高、但特徵獨立性假設可能不成立。
- 嘗試使用其他數據集，例如文本分類數據集（使用 MultinomialNB 或 BernoulliNB），來進行貝氏分類分析。
- 解釋不同的樸素貝葉斯變體，例如多項式樸素貝葉斯和伯努利樸素貝葉斯，以及它們適用於哪些類型的數據。
- 討論樸素貝葉斯分類的應用場景，例如垃圾郵件過濾和情感分析。
- 了解Laplace平滑，來處理訓練資料中，某個特徵在某個分類中沒有出現過的問題。
---

Naive Bayes 分類器屬於分類器系列，與線性模型很相似。然而，他們在訓練中往往速度更快。這種效率的代價是，Navie Bayes模型通常提供的泛化性能比邏輯回歸和線性 SVM 等線性分類器略差。單純貝氏模型之所以高效，是因為它們在學習參數時，僅針對每個特徵獨立地進行分析，並從每個特徵中收集簡單的類別統計數據。

### **高效的原因**

1. 獨立看待特徵：單純貝氏模型在訓練時，將數據的每個特徵（例如年齡、收入等）視為相互獨立的，不考慮特徵之間的複雜關係，這簡化了計算。

2. 簡單的統計計算：對於每個特徵，模型只計算與類別（例如「是」或「否」）相關的簡單統計量（如平均值、出現頻率等），而不是進行複雜的參數優化。

3. 高效性：由於這種方法避免了繁重的計算，單純貝氏模型在訓練和預測時速度很快，特別適合處理`高維數據`。

### scikit-learn 中實作了三種樸素貝葉斯分類器：

- **GaussianNB(高斯單純貝氏)**  
- **BernoulliNB(伯努利單純貝氏)**  
- **MultinomialNB(多元單純貝氏)**  

**這3個的特性,適用的數據類型和常見應用場景**

1. **GaussianNB(高斯單純貝氏)：**
	- 適用數據：連續數據（continuous data），即數值可以是任意實數，例如身高、溫度、考試分數等。  

	- 假設：每個特徵的數據分佈符合高斯分佈（即常態分佈）。  

	- 用途：當特徵是連續值時使用，例如預測某人的體重是否屬於某個範圍。

2. **BernoulliNB(伯努利單純貝氏)：**
	- 適用數據：：二元數據（binary data），即特徵只有兩個值（通常是 0 或 1），表示某事物是否存在，例如「是否出現某個單詞」。 
	-  
	- 假設：每個特徵是獨立的二元變量。 
	-  
	- 用途：常用於文本分類，特別是當我們只關心某個單詞是否出現在文本中（而非次數）。  

3. **MultinomialNB(多元單純貝氏)**

	- 適用數據：計數數據（count data），即特徵表示某事物出現的整數次數，例如單詞在一篇文章中的出現次數。 

	- 假設：特徵值是離散的計數，分佈符合多元分佈。  

	- 用途：也常用於文本分類，特別是當我們需要考慮單詞出現的頻率時。

> [!IMPORTANT]
> 文本分類的應用：  
> BernoulliNB 和 MultinomialNB 特別適合處理文本數據，因為文本數據通常可以表示為單詞的存在與否（二元）或出現次數（計數）。  
> GaussianNB 較少用於文本分類，因為文本特徵通常不是連續值。  


### **範例**
以下是三種模型的應用場景，搭配簡單的例子來說明它們的使用時機：

1. **GaussianNB(高斯單純貝氏)**:
	- 場景：預測某人是否患有糖尿病。
	- 數據：特徵包括連續值，如「血糖濃度」（例如 120.5 mg/dL）、「血壓」（例如 130/80 mmHg）、「體重」（例如 70.2 公斤）。
	- 為什麼使用 GaussianNB：這些特徵是連續的，且可以假設它們近似符合高斯分佈。
	- 模型行為：GaussianNB 會根據每個特徵的連續值計算概率，判斷是否屬於「糖尿病」類別。
	- 範例數據：  

```
特徵：血糖濃度 = 140.3, 血壓 = 135/85, 體重 = 75.1
類別：糖尿病 = 是
```
	
2. **BernoulliNB(伯努利NB)**
	- 場景：判斷一封電子郵件是否為垃圾郵件。
	- 數據：特徵是某些關鍵詞是否出現在郵件中（0 = 不存在，1 = 存在），例如「免費」「贏獎」「立即」。
	- 為什麼使用 BernoulliNB：我們只關心這些關鍵詞是否出現，而不關心出現次數，數據是二元的。
	- 模型行為：BernoulliNB 會根據關鍵詞的存在與否計算郵件屬於「垃圾郵件」的概率。
  - 範例數據：

```
特徵：免費 = 1, 贏獎 = 0, 立即 = 1
類別：垃圾郵件 = 是
```
	
3. **MultinomialNB(多元單純貝氏)**

- 場景：將新聞文章分類為「正面」或「負面」情緒。
- 數據：特徵是某些單詞在文章中的出現次數，例如「快樂」出現 3 次、「悲傷」出現 0 次、「美好」出現 2 次。
- 為什麼使用 MultinomialNB：我們關心單詞出現的頻率，數據是計數形式的。
- 模型行為：MultinomialNB 會根據單詞的出現次數計算文章屬於「正面」情緒的概率。
- 範例數據：

```
特徵：快樂 = 3, 悲傷 = 0, 美好 = 2
類別：情緒 = 正面
```

---

## GaussianNB實作
[**GaussianNB Model實作**](./sklearn實作1.ipynb) 
 
[**MNIST 手寫數字數據集**實作](./sklearn實作2.ipynb)
