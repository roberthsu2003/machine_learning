# 貝氏分類 Naive Bayes Classifier

貝氏分類（Naive Bayes Classifier）是機器學習中非常經典且直觀的分類演算法，適合用來做為學生入門機率與機器學習思維的橋樑。以下是教學時可以使用的介紹方式與學習重點：

## 重點:
- 解釋貝氏定理和樸素貝葉斯分類的基本概念，包括條件機率和特徵獨立性假設。
- 解釋高斯樸素貝葉斯如何處理連續型特徵。
- 解樸素貝葉斯分類的優缺點，例如簡單高效、對數據量要求不高、但特徵獨立性假設可能不成立。
- 嘗試使用其他數據集，例如文本分類數據集（使用 MultinomialNB 或 BernoulliNB），來進行貝氏分類分析。
- 解釋不同的樸素貝葉斯變體，例如多項式樸素貝葉斯和伯努利樸素貝葉斯，以及它們適用於哪些類型的數據。
- 討論樸素貝葉斯分類的應用場景，例如垃圾郵件過濾和情感分析。
- 了解Laplace平滑，來處理訓練資料中，某個特徵在某個分類中沒有出現過的問題。
---

## **介紹貝氏分類**

### **1. 從生活中的例子出發**

**垃圾郵件分類**：

> 給定一封電子郵件，根據裡面的文字內容，判斷它是垃圾郵件還是正常郵件。

**醫生根據症狀判斷**：

> 醫生根據症狀（咳嗽、發燒、喉嚨痛）來判斷病人可能得的是感冒還是流感。

### **2. 引入貝氏定理（Bayes’ Theorem）**

介紹：
```
P(A|B) = [P(B|A) * P(A)] / P(B)
```

意義：

- P(A)：先驗機率（事前對事件 A 的認知）
- P(B|A)：似然（在 A 發生的前提下，B 發生的機率）
- P(A|B)：後驗機率（觀察到 B 發生後，A 發生的機率）


🎯 實例：醫院檢測疾病的機率

**問題描述**

一種疾病的盛行率為 1%（也就是每 100 人中有 1 人患病），現在有一種檢測方法，檢測結果如下：

•	若病人真的有病，檢測為陽性的機率是 99%（靈敏度)  
 
•	若病人沒有病，檢測仍然有 5% 機率誤判為陽性（假陽性率）  

**現在問題來了：**

一個人檢測結果為「陽性」，那他實際上真的有病的機率是多少？



🧮 套用貝氏定理

令：  
	•	A：有這個病  
	•	B：檢測結果為陽性  

根據貝氏定理：  

```
P(A|B) = [P(B|A) * P(A)] / P(B)
```

帶入數值：  
- P(A) = 0.01      → 有病的機率（先驗機率）
- P(B|A) = 0.99      → 有病者檢測陽性的機率（似然）
- P(B|¬A) = 0.05     → 無病者誤檢為陽性的機率（假陽性率）
- P(¬A) = 0.99       → 無病的機率（1 - P(A)）

 計算 P(B)：總體陽性機率  

```
P(B) = P(B|A) * P(A) + P(B|¬A) * P(¬A)  
     = 0.99 * 0.01 + 0.05 * 0.99  
     = 0.0099 + 0.0495  
     = 0.0594
```

計算 P(A|B)：給定陽性結果後，實際有病的機率

```
P(A|B) = (0.99 * 0.01) / 0.0594  
       = 0.0099 / 0.0594  
       ≈ 0.1667  
```

✅ 結論

即使檢測結果是「陽性」，這個人真正有病的機率也只有 約 16.7%！

檢測準確率高達 99%，但實際得病的機率卻這麼低？

⸻

📌 重點補充
	•	原因在於這個病的「盛行率」很低，所以就算檢測誤判率不高，但「被誤判為陽性」的人數遠大於實際的病患人數。   
	•	先驗機率 和 後驗機率 的差別，以及為什麼「檢測結果不能完全代表事實」。

### **3. 解釋「Naive」的假設**

- 我們假設所有特徵是**條件獨立**的。
- 雖然這是假設，但在實務上效果常常「出奇地好」。


---

## 實作
[**GaussianNB Model實作**](./sklearn實作1.ipynb) 
 
[**MNIST 手寫數字數據集**實作](./sklearn實作2.ipynb)
