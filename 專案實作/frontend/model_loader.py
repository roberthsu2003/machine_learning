"""
æ¨¡å‹è¼‰å…¥å™¨
è² è²¬è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹ä¸¦æä¾›é æ¸¬æ¥å£
"""

import os
import sys
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import joblib
from typing import Dict, List, Tuple, Optional, Any

# æ·»åŠ æ¨¡å‹è¨“ç·´ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append('../model_training')
from models import IrisClassifier, create_model

class ModelLoader:
    """
    æ¨¡å‹è¼‰å…¥å™¨é¡
    è² è²¬è¼‰å…¥å’Œç®¡ç†æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹
    """
    
    def __init__(self, models_path='../models/'):
        """
        åˆå§‹åŒ–æ¨¡å‹è¼‰å…¥å™¨
        
        Args:
            models_path: æ¨¡å‹æ–‡ä»¶è·¯å¾‘
        """
        self.models_path = models_path
        self.models = {}
        self.scaler = None
        self.metadata = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # æ¨¡å‹é…ç½®
        self.model_configs = {
            'knn': {'name': 'K-è¿‘é„°åˆ†é¡å™¨', 'type': 'traditional'},
            'random_forest': {'name': 'éš¨æ©Ÿæ£®æ—', 'type': 'traditional'},
            'svm': {'name': 'æ”¯æ´å‘é‡æ©Ÿ', 'type': 'traditional'},
            'pytorch': {'name': 'PyTorch ç¥ç¶“ç¶²è·¯', 'type': 'pytorch'}
        }
    
    def load_all_models(self) -> bool:
        """
        è¼‰å…¥æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹
        
        Returns:
            bool: æ˜¯å¦è¼‰å…¥æˆåŠŸ
        """
        try:
            print("ğŸ”„ è¼‰å…¥æ¨¡å‹...")
            
            # è¼‰å…¥å…ƒæ•¸æ“š
            self.metadata = joblib.load(os.path.join(self.models_path, 'metadata.pkl'))
            print("âœ… å…ƒæ•¸æ“šè¼‰å…¥æˆåŠŸ")
            
            # è¼‰å…¥æ¨™æº–åŒ–å™¨
            self.scaler = joblib.load(os.path.join(self.models_path, 'scaler.pkl'))
            print("âœ… æ¨™æº–åŒ–å™¨è¼‰å…¥æˆåŠŸ")
            
            # è¼‰å…¥å‚³çµ±æ¨¡å‹
            traditional_models = ['knn', 'random_forest', 'svm']
            for model_name in traditional_models:
                model_path = os.path.join(self.models_path, f'{model_name}_model.pkl')
                if os.path.exists(model_path):
                    self.models[model_name] = joblib.load(model_path)
                    print(f"âœ… {self.model_configs[model_name]['name']} è¼‰å…¥æˆåŠŸ")
                else:
                    print(f"âš ï¸ æ‰¾ä¸åˆ° {model_name} æ¨¡å‹æ–‡ä»¶")
            
            # è¼‰å…¥ PyTorch æ¨¡å‹
            pytorch_path = os.path.join(self.models_path, 'pytorch_model.pth')
            if os.path.exists(pytorch_path):
                pytorch_model = create_model(model_type='complex')
                pytorch_model.load_state_dict(torch.load(pytorch_path, map_location=self.device))
                pytorch_model.eval()
                pytorch_model.to(self.device)
                self.models['pytorch'] = pytorch_model
                print(f"âœ… {self.model_configs['pytorch']['name']} è¼‰å…¥æˆåŠŸ")
            else:
                print("âš ï¸ æ‰¾ä¸åˆ° PyTorch æ¨¡å‹æ–‡ä»¶")
            
            print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
            return False
    
    def get_available_models(self) -> List[str]:
        """
        ç²å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
        
        Returns:
            List[str]: å¯ç”¨æ¨¡å‹åç¨±åˆ—è¡¨
        """
        return list(self.models.keys())
    
    def get_model_info(self) -> Dict[str, Dict[str, Any]]:
        """
        ç²å–æ¨¡å‹è³‡è¨Š
        
        Returns:
            Dict: æ¨¡å‹è³‡è¨Šå­—å…¸
        """
        info = {}
        for model_name in self.get_available_models():
            info[model_name] = {
                'name': self.model_configs[model_name]['name'],
                'type': self.model_configs[model_name]['type'],
                'available': True
            }
        return info
    
    def predict_single_model(self, model_name: str, X: np.ndarray) -> Tuple[np.ndarray, Optional[np.ndarray]]:
        """
        ä½¿ç”¨å–®å€‹æ¨¡å‹é€²è¡Œé æ¸¬
        
        Args:
            model_name: æ¨¡å‹åç¨±
            X: è¼¸å…¥ç‰¹å¾µ (å·²æ¨™æº–åŒ–)
            
        Returns:
            Tuple: (é æ¸¬é¡åˆ¥, é æ¸¬æ©Ÿç‡)
        """
        if model_name not in self.models:
            raise ValueError(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨")
        
        model = self.models[model_name]
        
        if model_name == 'pytorch':
            # PyTorch æ¨¡å‹é æ¸¬
            with torch.no_grad():
                X_tensor = torch.FloatTensor(X).to(self.device)
                outputs = model(X_tensor)
                probabilities = torch.softmax(outputs, dim=1).cpu().numpy()
                _, predicted = torch.max(outputs, 1)
                predictions = predicted.cpu().numpy()
        else:
            # å‚³çµ±æ¨¡å‹é æ¸¬
            predictions = model.predict(X)
            if hasattr(model, 'predict_proba'):
                probabilities = model.predict_proba(X)
            else:
                probabilities = None
        
        return predictions, probabilities
    
    def predict_all_models(self, X: np.ndarray) -> Dict[str, Dict[str, Any]]:
        """
        ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ¨¡å‹é€²è¡Œé æ¸¬
        
        Args:
            X: è¼¸å…¥ç‰¹å¾µ (æœªæ¨™æº–åŒ–)
            
        Returns:
            Dict: æ‰€æœ‰æ¨¡å‹çš„é æ¸¬çµæœ
        """
        # æ¨™æº–åŒ–è¼¸å…¥
        X_scaled = self.scaler.transform(X)
        
        results = {}
        for model_name in self.get_available_models():
            try:
                predictions, probabilities = self.predict_single_model(model_name, X_scaled)
                
                results[model_name] = {
                    'predictions': predictions,
                    'probabilities': probabilities,
                    'model_name': self.model_configs[model_name]['name'],
                    'type': self.model_configs[model_name]['type']
                }
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹ {model_name} é æ¸¬å¤±æ•—: {str(e)}")
                results[model_name] = {
                    'predictions': None,
                    'probabilities': None,
                    'model_name': self.model_configs[model_name]['name'],
                    'type': self.model_configs[model_name]['type'],
                    'error': str(e)
                }
        
        return results
    
    def get_target_names(self) -> List[str]:
        """
        ç²å–é¡åˆ¥åç¨±
        
        Returns:
            List[str]: é¡åˆ¥åç¨±åˆ—è¡¨
        """
        if self.metadata is None:
            return ['å±±é³¶å°¾', 'è®Šè‰²é³¶å°¾', 'ç¶­å‰å°¼äºé³¶å°¾']
        return self.metadata['target_names']
    
    def get_feature_names(self) -> List[str]:
        """
        ç²å–ç‰¹å¾µåç¨±
        
        Returns:
            List[str]: ç‰¹å¾µåç¨±åˆ—è¡¨
        """
        if self.metadata is None:
            return ['è¼ç‰‡é•·åº¦ (å…¬åˆ†)', 'è¼ç‰‡å¯¬åº¦ (å…¬åˆ†)', 'èŠ±ç“£é•·åº¦ (å…¬åˆ†)', 'èŠ±ç“£å¯¬åº¦ (å…¬åˆ†)']
        return self.metadata['feature_names']
    
    def get_data_summary(self) -> Dict[str, Any]:
        """
        ç²å–æ•¸æ“šæ‘˜è¦
        
        Returns:
            Dict: æ•¸æ“šæ‘˜è¦è³‡è¨Š
        """
        if self.metadata is None:
            return {
                'n_samples': 150,
                'n_features': 4,
                'n_classes': 3,
                'feature_names': self.get_feature_names(),
                'target_names': self.get_target_names()
            }
        return self.metadata['data_summary']
    
    def analyze_predictions(self, predictions_dict: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æé æ¸¬çµæœ
        
        Args:
            predictions_dict: é æ¸¬çµæœå­—å…¸
            
        Returns:
            Dict: åˆ†æçµæœ
        """
        # æå–æ‰€æœ‰é æ¸¬çµæœ
        pred_values = {}
        for model_name, result in predictions_dict.items():
            if result['predictions'] is not None:
                pred_values[model_name] = result['predictions'][0]
        
        if not pred_values:
            return {'consensus': False, 'unique_predictions': [], 'agreement_rate': 0.0}
        
        # è¨ˆç®—ä¸€è‡´æ€§
        unique_predictions = list(set(pred_values.values()))
        consensus = len(unique_predictions) == 1
        
        # è¨ˆç®—åŒæ„ç‡
        if len(pred_values) > 1:
            most_common = max(set(pred_values.values()), key=list(pred_values.values()).count)
            agreement_rate = list(pred_values.values()).count(most_common) / len(pred_values)
        else:
            agreement_rate = 1.0
        
        # æŒ‰é æ¸¬åˆ†çµ„
        prediction_groups = {}
        for model_name, pred in pred_values.items():
            pred_name = self.get_target_names()[pred]
            if pred_name not in prediction_groups:
                prediction_groups[pred_name] = []
            prediction_groups[pred_name].append(model_name)
        
        return {
            'consensus': consensus,
            'unique_predictions': unique_predictions,
            'agreement_rate': agreement_rate,
            'prediction_groups': prediction_groups,
            'predictions': pred_values
        }

# å…¨å±€æ¨¡å‹è¼‰å…¥å™¨å¯¦ä¾‹
model_loader = ModelLoader()

def load_models() -> bool:
    """
    è¼‰å…¥æ‰€æœ‰æ¨¡å‹ï¼ˆå…¨å±€å‡½æ•¸ï¼‰
    
    Returns:
        bool: æ˜¯å¦è¼‰å…¥æˆåŠŸ
    """
    return model_loader.load_all_models()

def get_model_loader() -> ModelLoader:
    """
    ç²å–æ¨¡å‹è¼‰å…¥å™¨å¯¦ä¾‹
    
    Returns:
        ModelLoader: æ¨¡å‹è¼‰å…¥å™¨å¯¦ä¾‹
    """
    return model_loader

if __name__ == "__main__":
    # æ¸¬è©¦æ¨¡å‹è¼‰å…¥å™¨
    loader = ModelLoader()
    
    if loader.load_all_models():
        print("\nâœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸ!")
        
        # æ¸¬è©¦é æ¸¬
        test_data = np.array([[5.1, 3.5, 1.4, 0.2]])  # å±±é³¶å°¾ç¯„ä¾‹
        results = loader.predict_all_models(test_data)
        
        print("\nğŸ”® æ¸¬è©¦é æ¸¬çµæœ:")
        for model_name, result in results.items():
            if result['predictions'] is not None:
                pred_class = loader.get_target_names()[result['predictions'][0]]
                print(f"{result['model_name']}: {pred_class}")
            else:
                print(f"{result['model_name']}: é æ¸¬å¤±æ•—")
        
        # åˆ†æé æ¸¬ä¸€è‡´æ€§
        analysis = loader.analyze_predictions(results)
        print(f"\nğŸ“Š é æ¸¬ä¸€è‡´æ€§: {'æ˜¯' if analysis['consensus'] else 'å¦'}")
        print(f"åŒæ„ç‡: {analysis['agreement_rate']:.2%}")
    else:
        print("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—!")
