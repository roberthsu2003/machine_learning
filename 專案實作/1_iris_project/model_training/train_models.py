"""
ä¸»è¨“ç·´è…³æœ¬
è¨“ç·´å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä¸¦ä¿å­˜çµæœ
"""

import os
import sys
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
import joblib
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from models import IrisClassifier, create_model, count_parameters
from data_loader import IrisDataLoader, evaluate_model

class ModelTrainer:
    """
    æ¨¡å‹è¨“ç·´å™¨é¡
    è² è²¬è¨“ç·´å¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
    """
    
    def __init__(self, data_loader):
        """
        åˆå§‹åŒ–è¨“ç·´å™¨
        
        Args:
            data_loader: æ•¸æ“šè¼‰å…¥å™¨å¯¦ä¾‹
        """
        self.data_loader = data_loader
        self.models = {}
        self.results = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è¨­å‚™: {self.device}")
    
    def train_traditional_models(self, X_train, X_test, y_train, y_test):
        """
        è¨“ç·´å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
        
        Args:
            X_train: è¨“ç·´ç‰¹å¾µ
            X_test: æ¸¬è©¦ç‰¹å¾µ
            y_train: è¨“ç·´æ¨™ç±¤
            y_test: æ¸¬è©¦æ¨™ç±¤
        """
        print("\nğŸ¤– é–‹å§‹è¨“ç·´å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ¨¡å‹...")
        
        # å®šç¾©æ¨¡å‹é…ç½®
        model_configs = {
            'knn': {
                'model': KNeighborsClassifier(n_neighbors=3),
                'name': 'K-è¿‘é„°åˆ†é¡å™¨'
            },
            'random_forest': {
                'model': RandomForestClassifier(n_estimators=100, random_state=42),
                'name': 'éš¨æ©Ÿæ£®æ—åˆ†é¡å™¨'
            },
            'svm': {
                'model': SVC(probability=True, random_state=42),
                'name': 'æ”¯æ´å‘é‡æ©Ÿ'
            }
        }
        
        # è¨“ç·´æ¯å€‹æ¨¡å‹
        for model_key, config in model_configs.items():
            print(f"\nğŸ“š è¨“ç·´ {config['name']}...")
            
            # è¨“ç·´æ¨¡å‹
            model = config['model']
            model.fit(X_train, y_train)
            
            # é æ¸¬
            y_pred = model.predict(X_test)
            
            # è©•ä¼°
            accuracy = accuracy_score(y_test, y_pred)
            print(f"âœ… {config['name']} æº–ç¢ºç‡: {accuracy:.4f}")
            
            # ä¿å­˜æ¨¡å‹å’Œçµæœ
            self.models[model_key] = model
            self.results[model_key] = {
                'accuracy': accuracy,
                'predictions': y_pred,
                'model_name': config['name']
            }
    
    def train_pytorch_model(self, X_train, X_test, y_train, y_test, 
                           epochs=1000, learning_rate=0.01, model_type='complex'):
        """
        è¨“ç·´ PyTorch ç¥ç¶“ç¶²è·¯æ¨¡å‹
        
        Args:
            X_train: è¨“ç·´ç‰¹å¾µ
            X_test: æ¸¬è©¦ç‰¹å¾µ
            y_train: è¨“ç·´æ¨™ç±¤
            y_test: æ¸¬è©¦æ¨™ç±¤
            epochs: è¨“ç·´è¼ªæ•¸
            learning_rate: å­¸ç¿’ç‡
            model_type: æ¨¡å‹é¡å‹
        """
        print(f"\nğŸ§  é–‹å§‹è¨“ç·´ PyTorch ç¥ç¶“ç¶²è·¯æ¨¡å‹ ({model_type})...")
        
        # è½‰æ›ç‚º PyTorch å¼µé‡
        X_train_tensor = torch.FloatTensor(X_train).to(self.device)
        X_test_tensor = torch.FloatTensor(X_test).to(self.device)
        y_train_tensor = torch.LongTensor(y_train).to(self.device)
        y_test_tensor = torch.LongTensor(y_test).to(self.device)
        
        # å‰µå»ºæ¨¡å‹
        model = create_model(model_type=model_type).to(self.device)
        print(f"ğŸ“Š æ¨¡å‹åƒæ•¸æ•¸é‡: {count_parameters(model)}")
        
        # å®šç¾©æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        
        # è¨“ç·´æ¨¡å‹
        model.train()
        train_losses = []
        
        print(f"ğŸ”„ é–‹å§‹è¨“ç·´ ({epochs} è¼ª)...")
        for epoch in tqdm(range(epochs), desc="è¨“ç·´é€²åº¦"):
            optimizer.zero_grad()
            outputs = model(X_train_tensor)
            loss = criterion(outputs, y_train_tensor)
            loss.backward()
            optimizer.step()
            
            train_losses.append(loss.item())
            
            # æ¯100è¼ªé¡¯ç¤ºä¸€æ¬¡æå¤±
            if (epoch + 1) % 100 == 0:
                print(f"è¼ªæ¬¡ {epoch+1}/{epochs}, æå¤±: {loss.item():.4f}")
        
        # è©•ä¼°æ¨¡å‹
        model.eval()
        with torch.no_grad():
            outputs = model(X_test_tensor)
            _, predicted = torch.max(outputs, 1)
            y_pred = predicted.cpu().numpy()
        
        accuracy = accuracy_score(y_test, y_pred)
        print(f"âœ… PyTorch æ¨¡å‹æº–ç¢ºç‡: {accuracy:.4f}")
        
        # ä¿å­˜æ¨¡å‹å’Œçµæœ
        self.models['pytorch'] = model
        self.results['pytorch'] = {
            'accuracy': accuracy,
            'predictions': y_pred,
            'model_name': 'PyTorch ç¥ç¶“ç¶²è·¯',
            'train_losses': train_losses
        }
        
        return train_losses
    
    def save_models(self, save_path='../models/'):
        """
        ä¿å­˜æ‰€æœ‰è¨“ç·´å¥½çš„æ¨¡å‹
        
        Args:
            save_path: ä¿å­˜è·¯å¾‘
        """
        print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹åˆ° {save_path}...")
        os.makedirs(save_path, exist_ok=True)
        
        # ä¿å­˜å‚³çµ±æ¨¡å‹
        for name, model in self.models.items():
            if name != 'pytorch':
                model_path = os.path.join(save_path, f'{name}_model.pkl')
                joblib.dump(model, model_path)
                print(f"âœ… {name.upper()} æ¨¡å‹å·²ä¿å­˜")
        
        # ä¿å­˜ PyTorch æ¨¡å‹
        if 'pytorch' in self.models:
            pytorch_path = os.path.join(save_path, 'pytorch_model.pth')
            torch.save(self.models['pytorch'].state_dict(), pytorch_path)
            print(f"âœ… PyTorch æ¨¡å‹å·²ä¿å­˜")
        
        # ä¿å­˜æ¨™æº–åŒ–å™¨
        self.data_loader.save_scaler(save_path)
        
        print(f"âœ… æ‰€æœ‰æ¨¡å‹å·²ä¿å­˜åˆ° {save_path}")
    
    def create_performance_report(self, target_names):
        """
        å‰µå»ºæ€§èƒ½å ±å‘Š
        
        Args:
            target_names: é¡åˆ¥åç¨±
        """
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¼ƒå ±å‘Š")
        print("=" * 50)
        
        # æŒ‰æº–ç¢ºç‡æ’åº
        sorted_results = sorted(self.results.items(), key=lambda x: x[1]['accuracy'], reverse=True)
        
        for i, (model_key, result) in enumerate(sorted_results, 1):
            print(f"{i}. {result['model_name']}: {result['accuracy']:.4f}")
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = sorted_results[0]
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[1]['model_name']} (æº–ç¢ºç‡: {best_model[1]['accuracy']:.4f})")
        
        return sorted_results
    
    def plot_training_curves(self, save_path='../models/'):
        """
        ç¹ªè£½è¨“ç·´æ›²ç·š
        
        Args:
            save_path: ä¿å­˜è·¯å¾‘
        """
        if 'pytorch' in self.results and 'train_losses' in self.results['pytorch']:
            # ç¢ºä¿ç›®éŒ„å­˜åœ¨
            os.makedirs(save_path, exist_ok=True)
            
            plt.figure(figsize=(10, 6))
            plt.plot(self.results['pytorch']['train_losses'])
            plt.title('PyTorch Model Training Loss Curve', fontsize=14)
            plt.xlabel('Epochs')
            plt.ylabel('Loss')
            plt.grid(True)
            
            curve_path = os.path.join(save_path, 'training_curve.png')
            plt.savefig(curve_path, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"âœ… è¨“ç·´æ›²ç·šå·²ä¿å­˜åˆ° {curve_path}")

def main():
    """
    ä¸»è¨“ç·´æµç¨‹
    """
    print("ğŸš€ é–‹å§‹æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´æµç¨‹...")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ•¸æ“šè¼‰å…¥å™¨
    data_loader = IrisDataLoader()
    
    # è¼‰å…¥æ•¸æ“š
    print("ğŸ“¥ è¼‰å…¥ Iris æ•¸æ“šé›†...")
    iris_data = data_loader.load_data()
    
    # é¡¯ç¤ºæ•¸æ“šæ‘˜è¦
    summary = data_loader.get_data_summary(iris_data)
    print(f"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆ:")
    print(f"   - æ¨£æœ¬æ•¸: {summary['n_samples']}")
    print(f"   - ç‰¹å¾µæ•¸: {summary['n_features']}")
    print(f"   - é¡åˆ¥æ•¸: {summary['n_classes']}")
    print(f"   - é¡åˆ¥åˆ†ä½ˆ: {summary['class_distribution']}")
    
    # åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²æ•¸æ“š...")
    X_train, X_test, y_train, y_test = data_loader.split_data(
        iris_data['data'], iris_data['target']
    )
    print(f"âœ… æ•¸æ“šåˆ†å‰²å®Œæˆ:")
    print(f"   - è¨“ç·´é›†: {X_train.shape}")
    print(f"   - æ¸¬è©¦é›†: {X_test.shape}")
    
    # æ¨™æº–åŒ–æ•¸æ“š
    print("\nğŸ”§ æ¨™æº–åŒ–æ•¸æ“š...")
    X_train_scaled = data_loader.fit_transform_data(X_train)
    X_test_scaled = data_loader.transform_data(X_test)
    print("âœ… æ•¸æ“šæ¨™æº–åŒ–å®Œæˆ")
    
    # åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = ModelTrainer(data_loader)
    
    # è¨“ç·´å‚³çµ±æ¨¡å‹
    trainer.train_traditional_models(X_train_scaled, X_test_scaled, y_train, y_test)
    
    # è¨“ç·´ PyTorch æ¨¡å‹
    trainer.train_pytorch_model(X_train_scaled, X_test_scaled, y_train, y_test)
    
    # å‰µå»ºæ€§èƒ½å ±å‘Š
    trainer.create_performance_report(iris_data['target_names'])
    
    # ç¹ªè£½è¨“ç·´æ›²ç·š
    trainer.plot_training_curves()
    
    # ä¿å­˜æ‰€æœ‰æ¨¡å‹
    trainer.save_models()
    
    # ä¿å­˜å…ƒæ•¸æ“š
    data_loader.save_metadata(iris_data)
    
    print("\nğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆï¼")
    print("=" * 60)
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - ../models/knn_model.pkl")
    print("   - ../models/random_forest_model.pkl") 
    print("   - ../models/svm_model.pkl")
    print("   - ../models/pytorch_model.pth")
    print("   - ../models/scaler.pkl")
    print("   - ../models/metadata.pkl")
    print("   - ../models/training_curve.png")

if __name__ == "__main__":
    main()
