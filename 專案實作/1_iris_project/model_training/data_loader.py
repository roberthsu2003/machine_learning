"""
æ•¸æ“šè¼‰å…¥å’Œé è™•ç†æ¨¡çµ„
è² è²¬è¼‰å…¥ Iris æ•¸æ“šé›†ä¸¦é€²è¡Œé è™•ç†
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os

class IrisDataLoader:
    """
    Iris æ•¸æ“šé›†è¼‰å…¥å’Œé è™•ç†é¡
    """
    
    def __init__(self, test_size=0.2, random_state=42):
        """
        åˆå§‹åŒ–æ•¸æ“šè¼‰å…¥å™¨
        
        Args:
            test_size: æ¸¬è©¦é›†æ¯”ä¾‹
            random_state: éš¨æ©Ÿç¨®å­
        """
        self.test_size = test_size
        self.random_state = random_state
        self.scaler = StandardScaler()
        self.is_fitted = False
        
        # ä¸­æ–‡åç¨±æ˜ å°„
        self.chinese_names = {
            'setosa': 'å±±é³¶å°¾',
            'versicolor': 'è®Šè‰²é³¶å°¾',
            'virginica': 'ç¶­å‰å°¼äºé³¶å°¾'
        }
        
        self.chinese_feature_names = {
            'sepal length (cm)': 'è¼ç‰‡é•·åº¦ (å…¬åˆ†)',
            'sepal width (cm)': 'è¼ç‰‡å¯¬åº¦ (å…¬åˆ†)',
            'petal length (cm)': 'èŠ±ç“£é•·åº¦ (å…¬åˆ†)',
            'petal width (cm)': 'èŠ±ç“£å¯¬åº¦ (å…¬åˆ†)'
        }
    
    def load_data(self):
        """
        è¼‰å…¥ Iris æ•¸æ“šé›†
        
        Returns:
            dict: åŒ…å«æ•¸æ“šå’Œå…ƒæ•¸æ“šçš„å­—å…¸
        """
        # è¼‰å…¥åŸå§‹æ•¸æ“š
        iris = load_iris()
        
        # å‰µå»ºä¸­æ–‡ç‰ˆæœ¬
        iris_data = {
            'data': iris.data,
            'target': iris.target,
            'target_names': [self.chinese_names[name] for name in iris.target_names],
            'feature_names': [self.chinese_feature_names[name] for name in iris.feature_names],
            'DESCR': iris.DESCR,
            'original_target_names': iris.target_names,
            'original_feature_names': iris.feature_names
        }
        
        return iris_data
    
    def split_data(self, X, y, stratify=True):
        """
        åˆ†å‰²æ•¸æ“šç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
        
        Args:
            X: ç‰¹å¾µæ•¸æ“š
            y: æ¨™ç±¤æ•¸æ“š
            stratify: æ˜¯å¦ä½¿ç”¨åˆ†å±¤æŠ½æ¨£
            
        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        stratify_param = y if stratify else None
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=self.test_size, 
            random_state=self.random_state,
            stratify=stratify_param
        )
        
        return X_train, X_test, y_train, y_test
    
    def fit_scaler(self, X_train):
        """
        æ“¬åˆæ¨™æº–åŒ–å™¨
        
        Args:
            X_train: è¨“ç·´æ•¸æ“š
        """
        self.scaler.fit(X_train)
        self.is_fitted = True
    
    def transform_data(self, X):
        """
        æ¨™æº–åŒ–æ•¸æ“š
        
        Args:
            X: è¦æ¨™æº–åŒ–çš„æ•¸æ“š
            
        Returns:
            æ¨™æº–åŒ–å¾Œçš„æ•¸æ“š
        """
        if not self.is_fitted:
            raise ValueError("æ¨™æº–åŒ–å™¨å°šæœªæ“¬åˆï¼Œè«‹å…ˆèª¿ç”¨ fit_scaler")
        
        return self.scaler.transform(X)
    
    def fit_transform_data(self, X_train):
        """
        æ“¬åˆä¸¦è½‰æ›è¨“ç·´æ•¸æ“š
        
        Args:
            X_train: è¨“ç·´æ•¸æ“š
            
        Returns:
            æ¨™æº–åŒ–å¾Œçš„è¨“ç·´æ•¸æ“š
        """
        X_train_scaled = self.scaler.fit_transform(X_train)
        self.is_fitted = True
        return X_train_scaled
    
    def get_data_summary(self, iris_data):
        """
        ç²å–æ•¸æ“šæ‘˜è¦è³‡è¨Š
        
        Args:
            iris_data: æ•¸æ“šå­—å…¸
            
        Returns:
            dict: æ•¸æ“šæ‘˜è¦
        """
        summary = {
            'n_samples': iris_data['data'].shape[0],
            'n_features': iris_data['data'].shape[1],
            'n_classes': len(iris_data['target_names']),
            'class_distribution': np.bincount(iris_data['target']),
            'feature_names': iris_data['feature_names'],
            'target_names': iris_data['target_names']
        }
        
        return summary
    
    def create_dataframe(self, X, y, feature_names, target_names):
        """
        å‰µå»º DataFrame ç”¨æ–¼è¦–è¦ºåŒ–
        
        Args:
            X: ç‰¹å¾µæ•¸æ“š
            y: æ¨™ç±¤æ•¸æ“š
            feature_names: ç‰¹å¾µåç¨±
            target_names: é¡åˆ¥åç¨±
            
        Returns:
            pd.DataFrame: åŒ…å«ç‰¹å¾µå’Œæ¨™ç±¤çš„ DataFrame
        """
        df = pd.DataFrame(X, columns=feature_names)
        df['å“ç¨®'] = [target_names[i] for i in y]
        return df
    
    def save_metadata(self, iris_data, save_path='../models/'):
        """
        ä¿å­˜æ•¸æ“šå…ƒæ•¸æ“š
        
        Args:
            iris_data: æ•¸æ“šå­—å…¸
            save_path: ä¿å­˜è·¯å¾‘
        """
        os.makedirs(save_path, exist_ok=True)
        
        metadata = {
            'target_names': iris_data['target_names'],
            'feature_names': iris_data['feature_names'],
            'original_target_names': iris_data['original_target_names'],
            'original_feature_names': iris_data['original_feature_names'],
            'data_summary': self.get_data_summary(iris_data)
        }
        
        joblib.dump(metadata, os.path.join(save_path, 'metadata.pkl'))
        print(f"âœ… å…ƒæ•¸æ“šå·²ä¿å­˜åˆ° {save_path}metadata.pkl")
    
    def save_scaler(self, save_path='../models/'):
        """
        ä¿å­˜æ¨™æº–åŒ–å™¨
        
        Args:
            save_path: ä¿å­˜è·¯å¾‘
        """
        if not self.is_fitted:
            raise ValueError("æ¨™æº–åŒ–å™¨å°šæœªæ“¬åˆ")
        
        os.makedirs(save_path, exist_ok=True)
        joblib.dump(self.scaler, os.path.join(save_path, 'scaler.pkl'))
        print(f"âœ… æ¨™æº–åŒ–å™¨å·²ä¿å­˜åˆ° {save_path}scaler.pkl")

def evaluate_model(y_true, y_pred, target_names, model_name="æ¨¡å‹"):
    """
    è©•ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        y_true: çœŸå¯¦æ¨™ç±¤
        y_pred: é æ¸¬æ¨™ç±¤
        target_names: é¡åˆ¥åç¨±
        model_name: æ¨¡å‹åç¨±
        
    Returns:
        dict: è©•ä¼°çµæœ
    """
    accuracy = accuracy_score(y_true, y_pred)
    
    print(f"\nğŸ“Š {model_name} è©•ä¼°çµæœ:")
    print(f"æº–ç¢ºç‡: {accuracy:.4f}")
    
    # åˆ†é¡å ±å‘Š
    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)
    
    # æ··æ·†çŸ©é™£
    cm = confusion_matrix(y_true, y_pred)
    
    results = {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': cm,
        'predictions': y_pred
    }
    
    return results

if __name__ == "__main__":
    # æ¸¬è©¦æ•¸æ“šè¼‰å…¥å™¨
    loader = IrisDataLoader()
    iris_data = loader.load_data()
    
    print("ğŸŒ¸ Iris æ•¸æ“šé›†è¼‰å…¥æˆåŠŸ!")
    print(f"æ¨£æœ¬æ•¸: {iris_data['data'].shape[0]}")
    print(f"ç‰¹å¾µæ•¸: {iris_data['data'].shape[1]}")
    print(f"é¡åˆ¥æ•¸: {len(iris_data['target_names'])}")
    print(f"é¡åˆ¥åç¨±: {iris_data['target_names']}")
    print(f"ç‰¹å¾µåç¨±: {iris_data['feature_names']}")
    
    # æ¸¬è©¦æ•¸æ“šåˆ†å‰²
    X_train, X_test, y_train, y_test = loader.split_data(iris_data['data'], iris_data['target'])
    print(f"\næ•¸æ“šåˆ†å‰²å®Œæˆ:")
    print(f"è¨“ç·´é›†: {X_train.shape}")
    print(f"æ¸¬è©¦é›†: {X_test.shape}")
    
    # æ¸¬è©¦æ¨™æº–åŒ–
    X_train_scaled = loader.fit_transform_data(X_train)
    X_test_scaled = loader.transform_data(X_test)
    print(f"\næ¨™æº–åŒ–å®Œæˆ:")
    print(f"è¨“ç·´é›†æ¨™æº–åŒ–å¾Œå½¢ç‹€: {X_train_scaled.shape}")
    print(f"æ¸¬è©¦é›†æ¨™æº–åŒ–å¾Œå½¢ç‹€: {X_test_scaled.shape}")
