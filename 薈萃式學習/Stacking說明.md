**Stacking** ((堆疊法或堆疊泛化)**的核心概念**

Stacking 是一種集成學習方法，它的核心思想是**「學習如何組合模型」**。與 Bagging（並行投票/平均）和 Boosting（串行專注錯誤）不同，Stacking 引入了一個**元模型 (meta-model)** 或稱為**第二層學習器 (level-1 model)**，這個元模型的任務是學習如何最好地結合多個**基礎模型 (base models)** 或稱為**第一層學習器 (level-0 models)** 的預測結果。

想像一下，你有一群不同領域的專家（基礎模型），他們各自對一個問題給出自己的判斷。現在，你不是簡單地讓他們投票，而是找來一位更有經驗的「總監」（元模型）。這位總監會觀察每位專家在不同情況下的表現，學習哪些專家的意見在什麼時候更值得信賴，或者如何將他們的意見巧妙地結合起來，以做出最終的、更優的決策。

**Stacking 的主要步驟：**

1. **準備數據集**：
    - 將原始訓練數據集分成兩部分：訓練集 (train set) 和測試集 (test set)。
    - 通常，為了訓練基礎模型並為元模型生成特徵，訓練集本身還會被進一步劃分（例如通過交叉驗證）。
1. **訓練基礎模型 (Level-0 Models)**：
    - 選擇多個不同的學習算法來構建基礎模型。這些模型最好是多樣化的，例如決策樹、支持向量機 (SVM)、K近鄰 (KNN)、邏輯回歸等。多樣性有助於元模型捕捉到不同方面的模式。
    - **關鍵點**：為了避免數據洩漏 (data leakage) 並為元模型生成「乾淨」的訓練數據，基礎模型的預測結果（用作元模型的輸入特徵）**不能**是它們在訓練自身時所用數據上的預測。通常採用以下方法之一：
        - **K-折交叉驗證 (K-Fold Cross-Validation)**：
            - 將訓練集分成 K 折。
            - 對於每一折：
                - 用 K-1 折的數據訓練基礎模型。
                - 用訓練好的基礎模型對剩下的一折（驗證折）進行預測。
            - 這樣，對於訓練集中的每個樣本，我們都得到了一個由「沒有見過該樣本」的模型所做出的預測。這些預測被稱為「out-of-fold (OOF)」預測。
            - 將所有 K 折的 OOF 預測組合起來，形成元模型的一個新的訓練特徵集。
        - **留出集 (Hold-out Set)**：
            - 將訓練集再分成一個較小的訓練子集 (sub-train) 和一個留出集 (hold-out/validation set)。
            - 用 sub-train 訓練基礎模型。
            - 用訓練好的基礎模型對 hold-out set 進行預測，這些預測將作為元模型的訓練特徵。
            - 這種方法相對簡單，但可能會浪費一些數據。
1. **創建新的特徵集 (給元模型使用)**：
    - 對於訓練集：使用步驟 2 中得到的 OOF 預測（或 hold-out set 上的預測）作為元模型的輸入特徵。如果有多個基礎模型，每個基礎模型的預測都會成為新特徵集的一列。
    - 對於測試集：用在**完整訓練集**上訓練好的基礎模型對原始測試集進行預測。這些預測將作為元模型在測試時的輸入特徵。
1. **訓練元模型 (Level-1 Model)**：
    - 使用步驟 3 中為訓練集創建的新特徵集（即基礎模型的 OOF 預測）以及原始訓練集的真實標籤來訓練元模型。
    - 元模型通常選擇一個相對簡單的模型，如邏輯回歸、線性回歸或一個不太複雜的樹模型，以避免過擬合這些由基礎模型產生的特徵。
1. **最終預測**：
    - 當有新的未見數據需要預測時：
        - 首先，讓所有基礎模型對新數據進行預測。
        - 然後，將這些基礎模型的預測結果作為輸入，餵給訓練好的元模型。
        - 元模型的輸出即為 Stacking 集成模型的最終預測結果。

**一個簡單易懂的小範例 (分類問題)**

假設我們要預測一個郵件是否為「垃圾郵件」(是/否)。我們有以下數據：

**原始訓練數據集 (Train_Full):**

| **郵件ID** | **特徵1 (詞頻)** | **特徵2 (大寫字母比例)** | **是否垃圾郵件 (實際)** |
| -------- | ------------ | ---------------- | --------------- |
| M1       | 0.5          | 0.1              | 否               |
| M2       | 0.0          | 0.8              | 是               |
| M3       | 0.9          | 0.6              | 是               |
| M4       | 0.2          | 0.2              | 否               |
| M5       | 0.7          | 0.3              | 是               |
| M6       | 0.1          | 0.0              | 否               |

**原始測試數據集 (Test_Full):**

| **郵件ID** | **特徵1 (詞頻)** | **特徵2 (大寫字母比例)** |
| -------- | ------------ | ---------------- |
| T1       | 0.6          | 0.7              |
| T2       | 0.3          | 0.1              |

**步驟 1 & 2: 訓練基礎模型 (使用 2-折交叉驗證生成 OOF 預測)**

假設我們選擇兩個基礎模型：

- **Base_Model_A (例如：邏輯回歸)**
- **Base_Model_B (例如：決策樹)**

我們將 `Train_Full` 分成兩折：

- Fold 1: {M1, M2, M3}
- Fold 2: {M4, M5, M6}
- **迭代 1 (訓練用 Fold 2，預測 Fold 1):**
    - 用 {M4, M5, M6} 訓練 Base_Model_A (記為 A_fold2) 和 Base_Model_B (記為 B_fold2)。
    - 用 A_fold2 預測 {M1, M2, M3} -> 得到 P_A_M1, P_A_M2, P_A_M3 (例如：0.2, 0.9, 0.8)
    - 用 B_fold2 預測 {M1, M2, M3} -> 得到 P_B_M1, P_B_M2, P_B_M3 (例如：否, 是, 是)
- **迭代 2 (訓練用 Fold 1，預測 Fold 2):**
    - 用 {M1, M2, M3} 訓練 Base_Model_A (記為 A_fold1) 和 Base_Model_B (記為 B_fold1)。
    - 用 A_fold1 預測 {M4, M5, M6} -> 得到 P_A_M4, P_A_M5, P_A_M6 (例如：0.3, 0.6, 0.1)
    - 用 B_fold1 預測 {M4, M5, M6} -> 得到 P_B_M4, P_B_M5, P_B_M6 (例如：否, 是, 否)

**步驟 3: 創建新的特徵集 (給元模型使用)**

- **元模型的訓練集 (Meta_Train_Features):** 將上述 OOF 預測組合起來 (假設分類問題，我們將類別預測轉換為概率或0/1)：
    | 郵件ID | Pred_Base_A (OOF) | Pred_Base_B (OOF) | 是否垃圾郵件 (實際) |
    | :----- | :---------------- | :---------------- | :------------------ |
    | M1     | 0.2               | 0 (否)            | 否                  |
    | M2     | 0.9               | 1 (是)            | 是                  |
    | M3     | 0.8               | 1 (是)            | 是                  |
    | M4     | 0.3               | 0 (否)            | 否                  |
    | M5     | 0.6               | 1 (是)            | 是                  |
    | M6     | 0.1               | 0 (否)            | 否                  |
- **元模型的測試集 (Meta_Test_Features):**
    - 現在，我們用 **完整的 `Train_Full`** 數據集重新訓練 Base_Model_A (記為 A_full) 和 Base_Model_B (記為 B_full)。
    - 用 A_full 預測 `Test_Full` -> 得到 P_A_T1, P_A_T2 (例如：0.7, 0.2)
    - 用 B_full 預測 `Test_Full` -> 得到 P_B_T1, P_B_T2 (例如：是, 否)
    - Meta_Test_Features:
        | 郵件ID | Pred_Base_A | Pred_Base_B |
        | :----- | :---------- | :---------- |
        | T1     | 0.7         | 1 (是)      |
        | T2     | 0.2         | 0 (否)      |

**步驟 4: 訓練元模型 (Meta_Model)**

- 選擇一個元模型，例如一個簡單的邏輯回歸 (Meta_LR)。
- 使用 `Meta_Train_Features` 的 `Pred_Base_A (OOF)` 和 `Pred_Base_B (OOF)` 作為輸入特徵，`是否垃圾郵件 (實際)` 作為目標，來訓練 Meta_LR。
- Meta_LR 會學習如何根據 Base_Model_A 和 Base_Model_B 的預測來判斷郵件是否為垃圾郵件。例如，它可能學到：「如果 Base_Model_A 的預測概率很高，且 Base_Model_B 也預測為是，那麼最終結果很可能是垃圾郵件。」

**步驟 5: 最終預測**

對於 `Test_Full` 中的 T1 和 T2：

- 我們已經有了它們在 `Meta_Test_Features` 中的基礎模型預測。
- 將這些預測 (例如 T1: {Pred_Base_A=0.7, Pred_Base_B=1}) 輸入到訓練好的 Meta_LR 中。
- Meta_LR 會給出最終的預測結果 (例如，對 T1 預測為「是」，對 T2 預測為「否」)。

**Stacking 的優勢：**

- **潛在的更高性能**：通過學習如何組合不同模型的優勢，Stacking 有可能達到比任何單個基礎模型或簡單的投票/平均更好的性能。
- **靈活性**：可以堆疊任意數量和種類的基礎模型。

**Stacking 的挑戰：**

- **複雜性**：實現起來比 Bagging 或 Boosting 更複雜。
- **計算成本高**：需要訓練多個基礎模型，然後再訓練一個元模型。
- **過擬合風險**：如果元模型過於複雜，或者基礎模型的 OOF 預測生成不當，元模型可能會對基礎模型的預測過擬合。這就是為什麼元模型通常選擇較簡單的模型，並且 OOF 預測的生成至關重要。
- **數據量需求**：通常需要足夠的數據來有效地劃分並訓練所有層級的模型。

總之，Stacking 是一種強大的集成技術，它通過一個額外的學習階段來智能地組合多個模型的預測，旨在榨取模型組合的最後一點性能提升。